\documentclass[main.tex,fontsize=8pt,paper=a4,paper=portrait,DIV=calc,]{scrartcl}
\input{../ost-summary-template.tex}

\lstset{
    language={[x86masm]Assembler},
    style=code,
}

\begin{document}
\begin{table}[h!]
\section{\textbf{Processor interaction}}
\begin{tabular}{|m{0.2\linewidth}|m{0.755\linewidth}|}
\hline
\mc{Memory-bus} & \mc{This enumerates the memory, as it can't be attached to the cpu directly, it would simply be a too long string.} \\
\hline
\mc{Data-bus} & \mc{This bus handles the data of a memory address that either has been read, or we want to write to.} \\
\hline
\mc{Control-Signals} & \mc{These indicate if we want to write or read.}\\
\hline
\mc{} & \mc{\textcolor{Red}{Note that the processor only really interacts with the rest of the system with the databus, the rest is only used in order to make the interaction happen at all!}}\\
\hline
\mc{\textbf{Instruction Set}} & \mc{A processor has a certain instruction set, that accesses it's own immediate register as well as request data from cache/memory. This is also the problem with Intel and AMD, they can't opensource their hardware properly as the instruction set is licensed by intel to other vendors. Therefore all hail Risc-V!} \\
\hline
\mc{} & \mc{Instructions are something like copy value of x into y, or write value u into p. But, there is also the instruction to simply do nothing!} \\
\hline
\mc{Sequence} & \mc{Just as the name says, it's a sequence of instructions to do something more specific than writing a value. Programs for example are just sequences of instructions. As we know, this is stored inside memory and is as stated above accessed by memory-bus.} \\
\hline
\mc{cache} & \mc{extremely fast but small memory insdide the processor.} \\
\hline
\mc{register} & \mc{Special datastructure inside the cpu that is even faster and smaller than the cache.} \\
\hline
\mc{Machine-Code} & \mc{The machine code is simply the encoding which the Sequences have to be in, in order for the CPU to understand the instructions. This is also why ARM programs do not run on an x86 system. The memory instructions would not be readable by the cpu. Rosetta is essentially just decoding and encoding these instructions.} \\
\hline
\mc{System-clock-cycle} & \mc{The entire system runs by the processor clock-cycle, it has 2 states, one constant sate, where values can only be read, and one change-able state, where any other operation can be done.} \\
\hline
\mc{Processor-cycle} & \mc{ 1. Processor orders the instructions from the memory with pointer.\\
  2. Processor decodes the Operation and Operands from the instruction.\\
  3. Processor chooses the corresponding core part (Baustein \#FuckGerman).\\
  4. Active Core might read from register.\\
  5. Active Core (part of it) executes operation.\\
  6. Active Core might write to register.\\
  7. Processor moves pointer according to operation size.\\
} \\
\hline
\mc{Encoding of Operations} & \mc{\pictext{2022-09-23-03:58:36.png}{The left side is a chain consisting of the Operation code and the register code. For example: the operation code \(1B_h\) will be combined with the register \(02_h\). This will combine like this in binary: \(011011_b\) append \(01\) -> \(01101101\) which is \(6D_h\) }[0.2,0.3,0.55]} \\
\hline
Little Endian Intel & Intel uses Little Endian due to certain benefits with this mode. \newline
\textbf{\emph{The biggest benefit is the fact that byte, word, dword all have the same address!}}\newline
\textbf{\emph{Remember from digicode, little endian is. \( s_1s_0\) \(s_3s_2\)}}\newline
\pic{2022-09-27-03:35:55.png}\\
\hline
Bit Byte and Word & Byte 8 Bit \newline 
Word 2 Byte / 16 Bit \newline
Doubleword 4 Byte / 32 Bit, or DWord \newline
Quadword 8 Byte / 64 Bit,or QWord \newline
Double Quadword 16 Byte / 128 Bit, or DQWord\\
\hline
Smallest Bit Count\newline
in the intel architecture & \textbf{The smallest amount that you can use in the intel architecture is 8bit}, in other words 1 byte. \newline You can't manipulate 1 single bit without taking 7 more with you.\\
\hline
\textbf{Register Formats} & \minipg{ 
In 16 bit architecture we have AH and AL registers, both being 8 bit.\newline
These accumulate to the \textbf{AX} Register.\newline
With 32 bit we get to \textbf{EAX} which extends the 16 bit by another 16 to the left.\newline
64 bit extends this further with another 32 and the name \textbf{RAX}.\newline
}{\pic{2022-10-04-03:34:45.png}}[0.5,0.5]\\
\hline
\end{tabular}
\end{table}
\pagebreak
\begin{table}[h!]
\begin{tabular}{|m{0,2\linewidth}|m{0.755\linewidth}|}
\hline
\emph{Further Terminology} & 
\minipg{
\begin{itemize}
  \item  \textbf{RAX} Accumulator for some operations, when none other is available
  \item  \textbf{RCX} Counter for loops or stringoperations
  \item  \textbf{RDX} Pointer for I/O Operations 
  \item  \textbf{RBX} Datapointer
  \item  \textbf{RSI,RDI} Source and Target-indices for stringoperations -> write your string to this
  \item  \textbf{RSP} Stackpointer, address for allocated stack
  \item  \textbf{RBP} Basepointer, address outside of stack, base for operation
  \item  \textbf{R8-R15} additional registers
\end{itemize}}
{\pic{2022-10-04-03:42:25.png}}[0.5,0.5]\\
\hline
\textbf{Length of Instruction} & 
\vspace{2mm}
\begin{itemize}
  \item Instructions are binary numbers which encode Operations and Operands
  \item Instructions can be 1-15 bytes long on the x86-64 architecture
  \item Count and size of parameters are dependend on the operation
  \item The length of an instruction is \textbf{not} included in the sequence
  \item A sequence must iterate through instructions to encode each instruction.\newline
  From start to finish.
  \vspace{-3mm}
\end{itemize}\\
\hline
\end{tabular}
\subsection{Operations}
\begin{tabular}{|m{0.2\linewidth}|m{0.755\linewidth}|}
\hline
\emph{Operations} & 
\vspace{2mm}
\begin{itemize}
  \item \textbf{Datatransfer Operations}
  \item \textbf{Arithmetic Operations}
  \item \textbf{Programflow Operations}
  \item \textbf{String Operations}
  \item \textbf{Operation for communication with the device}
  \item \textbf{Other Operations: Random Number Generator, Capability request}
  \vspace{-3mm}
\end{itemize}\\
\hline
\textbf{Runtime of Operations} & 
\vspace{2mm}
\begin{itemize}
  \item slowest Operations like Division take longer like 100 cycles. Some less than 1!
  \item Operations that need to access the memory need to wait for it,\newline
  this means that the runtime is variable: \newline
  \textbf{Operand in cache 4-70 cycles}\newline
  \textbf{Operand not in cache multiple hundreds of cycles!!}\newline
  \textcolor{red}{In other words a pc without a cache is useless!}
\item Not all operations can be optimized, others only with extensive measures like division.
  \vspace{-3mm}
\end{itemize}\\
\hline
Basics of CPUs & 
Cpus have 3 main functions:\newline
\begin{itemize}
\item \textcolor{purple}{move data to and from registers to memory}
\item \textcolor{purple}{calculate on registers}
\item \textcolor{purple}{change the instruction pointer}
\vspace{-3mm}
\end{itemize}\\ 
\hline
Early PCs and Memory & 
In early PCs, we used to directly access the main memory, which today would be extremely slow, today we rather access cache which handles the flow of data from the main memory to cache and back.\newline
\textcolor{OliveGreen}{The idea is basically that the cpu doesn't need to worry about the low level operation of handling the dataflow, it just takes the data and leaves it at that. This allows the CPU to significantly speed up, as it doesn't have to worry about this operation.}\newline
\includegraphics[scale=0.3]{2022-11-22-03:35:41.png}\\
\hline
Physical limiations of CPUs & 
The maximum speed of our signals in the cpu(latency) is light speed, but even this is only really theoretical, as most materials have a maximum speed of about a third of light speed.\newline
This means that we need to go closer and closer to the cpu, which is exactly what \textbf{chache does, it is closer to the CPU meaning there is less latency to access it!}\newline
This is also why new memeory is preferably built within the CPU die, as it makes the length of the wire shorter!\\
\hline 
Different Storage types & 
\textbf{There is persistent storage and fleeting storage}, persistant storage does not need any electricity to keep the data, for example HDDs, SSDs, USB sticks etc.\newline
They are usually slower but again offer the benefit of actually storing something.\newline
The other variant is fleeting storage, this is \textbf{WAY faster}, but it \textbf{can't store anything for longer than the PC is online for.}\\
\hline
Locality & 
Locality is the idea that if I used a variable in a program, then it is likely that i \textbf{will use this variable again, and that the next memory addresses after this variable will also be used at some point.}\newline
This means that these "local" addresses will be cached instead of stuck in slow memory, this makes it much faster to load heap allocated data!\newline
\begin{lstlisting}
for (int i = 0; i < n; i++) {
s = s + a[i];
}
m = s / n; 
\end{lstlisting}
\, \newline
\includegraphics[scale=0.4]{2022-11-22-03:53:06.png}\\
\hline
\end{tabular}
\end{table}
\pagebreak
\begin{table}[ht!]
\begin{tabular}{|m{0.2\linewidth}|m{0.755\linewidth}|}
\hline
Duties of memory and cache & 
\begin{itemize}
\item \textcolor{purple}{Processor and Cache}\newline
  \begin{itemize}
  \item \textcolor{white}{optimizes transport between main memory and registers}
  \item \textcolor{white}{speculates about future access on memory}
  \end{itemize} 
\item \textcolor{purple}{Compiler}\newline
  Registercontrol: defines when data is moved from memory to register and back
\item \textcolor{purple}{Operating System}\newline
  \begin{itemize}
    \item organizes the interaction with storage
    \item distributes memory to programs
    \end{itemize}
\vspace{-3mm}
\end{itemize}\\ 
\hline
Cache terms & 
\begin{itemize}
\item \textcolor{purple}{Cache-Size:} Count of usable Bytes\newline
  Space for addresses is also allocated, but not explicitly stated
\item \textcolor{purple}{Cache-Hit:} searched address found in cache
\item \textcolor{purple}{Cache-Miss:} searched address not found in cache\newline
  access memory instead!
\item \textcolor{purple}{\(T_C\):} Access time on Cache
\item \textcolor{purple}{\(T_M\):} Access time on Memory
\item \textcolor{purple}{\(P_C\):} Probability of a Cache-Hit (likely above 0.9)
\vspace{-3mm}
\end{itemize} \\
\hline
Calculation for median access time & 
\textcolor{red}{\(E(T) = P_C * T_C + (1 - P_C )* T_M\)}\newline
\textcolor{OliveGreen}{Access time on cache is about 1\% of the Access time on memory}\newline
\textcolor{OliveGreen}{Usually a program will get 95\% Cache-Hits}\\
\hline
Fully-Associative Cache & 
This cache stores an address for each byte, this is really fast, meaning that each individual address is cached, however it will leave a lot on the table in the sense that you need more cache to store things, and considering the fact that cache is expensive and small, this is likely not a good solution for everything:\newline
\includegraphics[scale=0.35]{2022-11-22-04:18:26.png}\newline
\textcolor{red}{Note the a is the address and d the value!}\newline
Lookup:\newline
\includegraphics[scale=0.35]{2022-11-22-04:20:02.png}\\
\hline
CacheLines & 
This essentially is a block of memory that will be stored in the cache instead of each byte itself. This means we can store more data with less memory addresses.\newline
The size of the block is therefore the same as the size of the line, otherwise this couldn't work.\newline
\textcolor{OliveGreen}{The idea here is that the lowest 6 bits of the address in the cache are 0, then we can use these 6 bits to encode the number 64, which is how many bytes we have.\newline 
  \textcolor{red}{Because of these 6 bit, we also need to divide the address taht we want to use by \(2^6\) which is \(4_h\)!\newline
  address in 64 cacheline = address in hex / 4 in hex}\newline
Then we can use this to encode each offset, which can then be used to get the actual address of the data via this offset:}\newline
\includegraphics[scale=0.35]{2022-11-22-04:30:41.png}\newline
It will \textbf{always check \(\text{t*} == \text{t}_\text{i}\) at the same time !}\newline
Here address = 84480801h -> divide by 4h -> 2112020h\newline
With the lower 6 bits being the offset j -> here 1\newline
\includegraphics[scale=0.35]{2022-11-22-04:34:35.png}\newline
Fully asociative cache are really good for async but are hard to implement.\newline
They often cost a lot of hardware when used in async mode, and otherwise would take longer when running in iterative mode!\\
\hline
Direct Mapping & 
With direct mapping we have all blocks being mapped to a line, while not every line is currently "active", the active part here is referring to the part of the cache that is actually filled with data.\newline
\includegraphics[scale=0.25]{2022-11-25-04:23:28.png}\\
\hline
\end{tabular}
\end{table}
\pagebreak
\begin{table}[ht!]
\begin{tabular}{|m{0.2\linewidth}|m{0.755\linewidth}|}
\hline
&
As you can see in direct mapping, you have the \textbf{first 4 bits pointing to the block number}, which here is 7, the \textbf{last 2 bits are pointing to the value, which is the third value 31}.\newline
In combination \textbf{the bits result in the value that the cell in the memeory holds!!}\newline
Note that this works with any memory size, as long as the block size is equal to the cache size, and the cache is big enough to store the amount of lines.\newline
The calculation is as follows:\newline
\begin{itemize}
  \item \textcolor{purple}{Bits for block numbers: \(log_2(\text{memory block count})\)}
  \item \textcolor{purple}{Bits for cell numbers: \( log_2(\text{cell count per block}) \)}
\end{itemize} 
\, \newline
\includegraphics[scale=0.3]{2022-11-25-04:30:25.png}\newline
Here we split the blocks into each line, meaning that one line will have multiple blocks assigned to it.\newline
However, this doesn't mean that we have multiple data from other blocks in the cache, it only means that they will be in that line should they be in the cache.\newline
\includegraphics[scale=0.3]{2022-11-25-04:35:20.png}\newline
Now we split the Block numbers into yet 2 more categories, \textbf{tag bits} and \textbf{line numbers}\newline
this can be done as all line numbers will map to the line, the \textbf{the first 2 bits are not necessary for this! See above!}\newline
This means that we can use the first two for something else, and we use them to indicate which block is actually in the cache currently:\newline
\includegraphics[scale=0.3]{2022-11-25-04:33:15.png}\newline
If the first 2 bits are both 0 and the second 2 are both 1, then it would map to 3.\newline
So it is important to know, that the first 2 bits will define a section of a line, 0, 1, 2 and 3 or 4, 5, 6 and 7 ... etc. While the next 2 bits define the actual line, 1 1 for the third line, 1 0 for the second line, etc.\\
\hline
Comparison Fully Associative Cache (FAC)\newline and Direct Mapped Cache (DMC) & 
The fully associative cache will only have tags and offsets, this is easier to map, but also requieres a bigger tag and more comparators!\newline
\textbf{In fact, per "way" we need one comparator!}\newline
\includegraphics[scale=0.25]{2022-11-25-04:43:36.png}\newline
Other differences: \newline
DMC has collisions, while the FAC will not, in other words 53 must be stored in the same address with direct mapping as 63, this is a collision! You can only overwrite in this case!
\\
\hline
Set-Associative-Cache (SAC) & 
The SAC is the middle ground between FAC and DMC, it provides multiple DMCs, namely k amount of DMC! (with k obviously being a variable number)\newline
\textcolor{red}{Note that all of the caches are as fast as the other, the only difference is complexity, therefore hardware requirements!}\\
\hline
\end{tabular}
\end{table}
\pagebreak
\begin{table}[ht!]
\section{HEAP vs STACK}
\begin{tabular}{|m{0.2\linewidth}|m{0.755\linewidth}|}
\hline
The problem & 
Many tasks require an \textbf{unknown amount of objects}, this can be anything from entities in games, photos in your file explorer to whatever else.\newline
How can we guarantee that we have enough memory ready to hold all of the data that can be thrown at us?\\
\hline
The naive solution & 
The naive solution is to simply \textbf{predefine how much we need and hardcode it.}\newline
\minipg{
\textcolor{green}{Pros:}\newline
\begin{itemize}
\item \textcolor{black}{Fast af!}
\item \textcolor{black}{Easy to implement}
\end{itemize} 
}{ 
\textcolor{red}{Negatives:}\newline
\begin{itemize}
\item \textcolor{black}{Hardcoded size! Crash or blocked at max size}
\item \textcolor{black}{can only be bigger by using a hardcoded bigger version!}
\end{itemize} 
}[0.4,0.4]\\
\hline
The dynamic stack solution & 
Theoretically you can also dynamically add your elements on your stack, this can be used for specific usecases where you don't know exactly how big your container will be, but you know that it will be lower than the max size of the stack, therefore guaranteeing that it won't crash!\newline
\begin{lstlisting}
void f () {
  size_t s = count_images();
  thumbnail_t *thumbnails = alloca (s * sizeof (thumbnail_t));
  create_thumbnails (thumbnails);
  display_thumbnails (thumbnails);
}
\end{lstlisting}
\, \newline
\minipg{
\textcolor{green}{Pros:}\newline
\begin{itemize}
\item \textcolor{black}{Fast af!}
\item \textcolor{black}{dynamic}
\end{itemize} 
}{ 
\textcolor{red}{Negatives:}\newline
\begin{itemize}
  \item \textcolor{black}{Hardcoded \textbf{max} size! Crash or blocked at max size}
  \item \textbf{Not standard!}
  \item Hard to implement!
\end{itemize} 
}[0.4,0.4]\\
\hline
Heap & 
The generic solution is the heap solution, this allocates a random space in memory for the specific use of this container.\newline
This allows us to dynamically increase the size, since we can always change the location and take up more memory as long as the OS has enough of it left.\newline
\minipg{
\textcolor{green}{Pros:}\newline
\begin{itemize}
\item \textcolor{black}{Dynamic}
\item \textcolor{black}{Limited only by the capacity of the Memory}
\end{itemize} 
}{ 
\textcolor{red}{Negatives:}\newline
\begin{itemize}
\item \textcolor{black}{slower than stack}
\item \textcolor{black}{Needs to be freed manually by many languages}
\item \textcolor{black}{Control with heap often leads to runtime checks \newline -> performance loss}
\end{itemize} 
}[0.4,0.4]\\
\hline
Implicit vs Explicit Memory freeing & 
Note, this is rather general, as rust does things differently to C and C++.\newline
\minipg{
Implicit:\newline
\begin{itemize}
\item \textcolor{black}{no memory leaks}
\item \textcolor{black}{not time deterministic}
\item \textcolor{black}{Overhead}
\end{itemize} 
}{ 
Explicit:\newline
\begin{itemize}
\item \textcolor{black}{Unsafe}
\item \textcolor{black}{faster}
\end{itemize} 
}[0.4,0.4]\newline
\textcolor{red}{Rust has a middle ground as it essentially has explicit memory handling with proper API, meaning you can't actually fuck up other than reference loops.}\\
\hline
Malloc and free & 
Malloc allocates memory and free deallocates it again.\newline
\begin{lstlisting}
#include <stdlib.h>
thumbnail_t *thumbnail = 0; // create pointer

void initialize_thumbnails() {
  size_t s = count_images();
  thumbnails = malloc(s * sizeof (thumbnail_t)); // allocate memory
  // thumbnails = malloc(sizeof (thumbnail_t [s])); also works
  // thumbnails = malloc(s * sizeof *thumbnail_t);  also works

  create_thumbnails(thumbnails);

  // at some point 
  free(thumbnails); // free memory
  thumbnails = 0;   // reset pointer
}
\end{lstlisting}\\
\hline
How does the OS allocate memory ? & 
When we call for 4 integers to be allocated, which would be 16bytes, how much would the OS allocate?
It will allocate one more \textbf{size\_t} in order to save the size of the allocated space.\newline
In other words, when called for 16 bytes, it will allocate 20 bytes, while 4 bytes are without data, they only serve as a representation of how much to free.\newline
\includegraphics[scale=0.4]{2022-11-29-03:48:59.png}\newline
\textcolor{orange}{Note, the pointer will always direct to the start of the 16 bytes that we wanted to allocate!}\\
\hline
Freeing & 
When freeing, we do not change the pointer, meaning that when we call something like: free(p);, then p will still have the same value, just that this pointer now has memory that no longer "belongs to us".\newline
We can still however call free again, which will lead to \textbf{undefined behavior! It might free random memory!}\\
\hline
Good Practise & 
In general, when you create a function that uses malloc, \textbf{immediately create a function that calls free!}\newline
\begin{lstlisting}
struct T *create_t() {
  struct T *t = malloc(sizeof (struct T));
  // something
  return t;
}

void destroy(struct T *t) {
 free(t);
}
\end{lstlisting}\\
\hline
\end{tabular}
\end{table}
\pagebreak 
\begin{table}[ht!]
\section{Fragmentation}
\begin{tabular}{|m{0.2\linewidth}|m{0.755\linewidth}|}
\hline
Internal Fragmentation & 
\textcolor{purple}{This happens with fixed block size!}\newline
\textcolor{purple}{This simply means the alloction of bigger blocks of memory than necessary, eg. 200bytes for something with the size of 5 bytes (extreme example)}\newline
\textcolor{red}{Often this is the case because the heap implementation can't allocate this specific size, eg. we wanted 12 bytes, but the heap implementation can only allocate multiples of 8, hence it allocates 16 and we lose 4 bytes.}\newline
Possible solutions, \textbf{runtime environments, but those cost performance}, better implementations like best fit.\\
\hline
External Fragmentation &
\textcolor{purple}{This happens with variable block size!}\newline
When programs get killed and free the memory, or when programs repeatedly free memory during runtime, then all the allocated blocks are now available again, but these blocks are not necessarily useful.\newline
\textcolor{orange}{One of the best solutions is to allocate memory once and then free everything, therefore not creating thousands of blocks that could fragment the memory.}\newline
Note that this solution can only be done properly if you have a sense of how much memory your program needs, otherwise you have the issue of having allocated unused memory, or you still need to reallocate again.\newline
Other solutions:\newline 
\begin{itemize}
\item \textcolor{black}{Runtimes.... performance..}
\item \textcolor{black}{using fixed block sizes}
\item \textcolor{black}{Better implementations of allocating memory}
\item \textcolor{black}{using your own heaps}
\item \textcolor{black}{Spawn objects at once and delete at once!}
\item \textcolor{black}{Composition over Aggregation -> combining of objects in your program}
\vspace{-3mm}
\end{itemize} 
\\
\hline
Heap Implementation Variants & 
There are many implementations, some practial, some optimized..\newline
\begin{itemize}
\item \textcolor{purple}{Base Variants}\newline
  \begin{itemize}
  \item \textcolor{black}{Variable Blocksize}
  \item \textcolor{black}{Fixed Blocksize}
  \item \textcolor{black}{Size Classes}
    Memory will only be allocated in specific sizes.\newline
    potences of \(2^0\) to \(2^n\)\newline
    numbers from 1 to m\newline
    All free sections in a class size will be listed in a list.
  \item \textcolor{black}{Budy-System}
  \end{itemize} 
\item \textcolor{purple}{Practical Heap Implementations}\newline
  Usually a combination of base variants:\newline
  \begin{itemize}
  \item \textcolor{black}{Hierarchical Chains}
  \item \textcolor{black}{Variety of different block sizes}
  \end{itemize} 
\item \textcolor{purple}{Optimized Heap Implementations}\newline
  \begin{itemize}
  \item \textcolor{black}{Depends on the use}
  \item \textcolor{black}{Heap implementations are constantly improved}
  \item \textcolor{black}{Sometimes you can choose the strategy -> penguinOS}
  \item \textcolor{black}{Sometimes a program can have more than one heap strategy}
  \end{itemize} 
\vspace{-3mm}
\end{itemize}\\ 
\hline
Fixed Blocksize & 
The easiest heap implementation is to just define a \textbf{base block size}, then you will only allocate multiples of that block size.\newline
\textcolor{green}{The benefit of this is that you can store the metedata for the heap allocation for cheap should you allocate a lot of memory}, on the other hand, should you allocate only a small chunk, then you might have a ratio of metadata to actual data of 50\%, which is shite.\newline
\includegraphics[scale=0.4]{2022-11-29-04:14:43.png} \newline
\\
\hline
Decentralized vs Centralized Metadata & 
When we store heap allocated data, we always need a way to store the information about how big this allocated memory is, etc.\newline
There are 2 ways to store this, \textbf{1. decentralized:}\newline
This means that we either store the \textbf{metadata before of after the allocated memory}, like the first implementation we talked about where you store an \textbf{additionalsize\_t for the metadata}.\newline
The other new variant is the \textbf{centralized version}, here we store the metadata in a \textbf{structure beyond the allocated memory}, this can be something like a \textbf{Linked List}. \newline
\textcolor{red}{Note this idea is general, not every heap implementation uses either of these concepts}\\
\hline
Memory-Management with Bit-lists & 
Here we just \textbf{use 1 bit of the block as a flag if the block is free or not.}\newline
\textcolor{orange}{Usually we use this via a \textbf{Linked List!}}\newline
We define the following metadata:\newline
\begin{itemize}
\item \textcolor{purple}{Status: free or used}
\item \textcolor{purple}{Start: address of first block of data}
\item \textcolor{purple}{Size: Count of blocks}
\item \textcolor{purple}{Next: Address of next Listelement}
\end{itemize} 
\, \newline
\includegraphics[scale=0.4]{2022-11-29-04:18:03.png}\newline
Since we use a linked list, we need to \textbf{iterate over the elements to see where we have enough space free!}\\
\hline
\end{tabular}
\end{table}
\pagebreak 
\begin{table}[ht!]
\begin{tabular}{|m{0.2\linewidth}|m{0.755\linewidth}|}
\hline
Recombination of free spaces & 
When freeing memory using a list with neighbours, we can always check if the previos or next neighbour is free, should this one be free as well, then we can combine this the block we want to free with the free nieghbour!\newline
The steps are the following:\newline
\begin{itemize}
\item \textcolor{black}{Previous element free: remove this element and extend previous}
\item \textcolor{black}{Next element free: remove next element and extend previous}
\item \textcolor{black}{None free: free this element}
\item \textcolor{black}{Both free: extend previous with this and next}
\vspace{-3mm}
\end{itemize} \\
\hline
Search Algorithms for free blocks &
\vspace{2mm}
\begin{itemize}
\item \textcolor{purple}{First Fit}\newline
  Take the first space that fits\newline
  This leads to many small empty spaces at the start
\item \textcolor{purple}{Next Fit}\newline
  Chooses first fitting space after last reserved space\newline
  Empty spaces everywhere, worse than First Fit
\item \textcolor{purple}{Best Fit}\newline
  Searches ALL empty spaces and chooses the smallest\newline
  Best coverage of memory, worst performance
\item \textcolor{purple}{Worst Fit}\newline
  Searches ALL spaces and chooses the biggest empty space\newline
  shit in general
\item \textcolor{purple}{Quick Fit}\newline
Fast reservation: first element of the list with the smallest fitting size\newline
Neighbours are often not easy to find, recombination of free spaces hard.
\vspace{-3mm}
\end{itemize} 
\, \newline
\textcolor{red}{Note these algorithms are general, not every heap implementation uses either of these concepts}\\
\hline
Buddy-System & 
\vspace{2mm}
\begin{itemize}   
\item A variant of the class size method.\newline
\item \(2^m\) is the smallest size class\newline
\item \(2^n\) is the entire memory\newline
\item At the start there is only the entire Memory, 
\end{itemize} 
\, \newline
\minipg{
\includegraphics[scale=0.3]{2022-11-29-05:19:44.png}
}{ 
At the start we have the full memory, then when we get an allocation request that is smaller than this size divided by 2, we split the memory into 2 sections, these 2 sections are now considered "buddies", as the merge into the bigger part together.\newline
Since we requested 64bytes from the max of 512 bytes, we can split again, and again, we do this until the split would be smaller than the size we want, this size will then be allocated.\newline
Each new value that should be allocated will be done in the same way.
}[0.37,0.37] 
\textcolor{orange}{When freeing memory, it will always be checked whether or not the "buddy" is also free, if it is, then the entire block can be combined and freed, otherwise only this block is freed.}\newline
Here is an example to check whether or not 2 addresses are buddies:\newline
Let's say we want to check if 2 addresses with the allocated size of 16KB are buddies.\newline
This means that we first need to \textbf{figure out what power k we are at}.\newline
This can be done by calculating 16KB, which is \(2^14\) -> 1 byte = 8 bit -> \(2^3\) bit, then multiple this by 10 and double it as 16 is 8 * 2.\newline
So, k = 14.\newline
\begin{lstlisting}
#include <stddef.h>
#include <stdio.h>

void expect(int a, int b) { fputs(a == b ? "OK\n" : "ERROR\n", stdout); }

int are_buddies(size_t a, size_t b, size_t level) {
  // shift k times until we get the binary number k 
  size_t bit_k = 1 << level; // k in binary

  // xor address a and b -> results in 1 bit being different, aka 1 bit being 1
  // example 110000000000000 and 100000000000000, the 14 bit is different
  // if this result is the same as bitk, then you have buddies
  // 010000000000000 and 10000000000000, note the left address has 1 leading 0!
  // leading 0s are ignored! treated as the same number!
  return (a ^ b) == bit_k ;
}

int main(int argc, char **argv) {
  expect(are_buddies(0, 1, 0), 1);
  expect(are_buddies(0, 0x40, 7), 0);
  expect(are_buddies(0, 0x40, 6), 1);
  expect(are_buddies(0, 0x40, 5), 0);
  expect(are_buddies(0xabd40, 0xabd00, 6), 1);
  expect(are_buddies(0x40, 0x40, 6), 0);
  expect(are_buddies(0x40, 0x40, 6), 0);
}
\end{lstlisting}\\
\hline
\end{tabular}
\end{table}
\pagebreak
\begin{table}[h!]
\begin{tabular}{|m{0,2\linewidth}|m{0.755\linewidth}|}
\hline
Object-Pools & 
\vspace{2mm}
\begin{itemize}
\item \textcolor{purple}{Entire memory(Page) is split into equal sized objects}
\item \textcolor{purple}{Interal fragmentation when objects are not proper divisions of the page}
\item \textcolor{purple}{No recombination as objects stay as the same size}
\item \textcolor{purple}{If new objects are needed, a new page is created and split into objects}
\item \textcolor{purple}{Free objects are listed in a list, usually also initialized}
\item \textcolor{purple}{Usually found in kernels for fixed objects}
\vspace{-3mm}
\end{itemize} \\
\hline
Memory Allocation in linux &
\vspace{2mm}
\begin{itemize}
\item \textcolor{orange}{Buddy-System for big allocations}\newline
  \begin{itemize}
\item smallest blocksize = 4kB
\item Other systems for smaller allocations
\item Subsystems can request multiple of Pagesize
\item malloc for user Applications
  \end{itemize} 
  \begin{itemize}
  \item \textcolor{black}{Part of the C standard library}
  \item \textcolor{black}{Variable block size with first fit and decentralized metadata}
  \item \textcolor{black}{Metadata before and after allocated memory to enable fast recombination}
  \end{itemize}
\item \textcolor{orange}{Object-Pools for kernel}\newline
\begin{itemize}
\item \textcolor{black}{objects are initialized}
\item \textcolor{black}{One pool per object type, with 3 lists, \newline
  full, partially full and empty slabs}
\item \textcolor{black}{Slab = Memory block from buddy system for objects of same type}
\item 3 Implementations: \textbf{\textcolor{red}{SLAB,SLOB,SLUB}}\newline
  SLAB, originally the only one\newline
  SLOB, created for embedded systems\newline
  SLUB, todays standard
\end{itemize} 
\vspace{-3mm}
\end{itemize} 
\\
\hline
Memory Allocation in Windows & 
\vspace{2mm}
\begin{itemize}
  \item \textcolor{orange}{FreeList[128]}\newline
    \begin{itemize}
    \item \textcolor{black}{Free sections are stored in pointer array of size 128}
    \item \textcolor{black}{FreeList[n]: pointer on linked list for all sections with n blocks}
    \item \textcolor{black}{FreeList[0]: pointer on linked list for all sections with 128 blocks}
    \end{itemize} 
\item \textcolor{orange}{Additional BitList for fast searching of lists that have free space}
\item \textcolor{orange}{Cache on entries on FreeList[0]}\newline
  Array with 896 elements for each possible sectionsize from 1kB to 8kB\newline
  Element i points to first element in FreeList[0] with size 8 * i + 1024
\item \textcolor{orange}{Bitmap over cache for fast searching of free sections}
\vspace{-3mm}
\end{itemize} 
\, \newline
\textcolor{orange}{Programs and heap in windows:}\newline 
\begin{itemize}
\item \textcolor{purple}{Programs can have two frontends, or optionally on the backend, which implement the heap}\newline
  Low-Fragmentation closed source heap shit
\item \textcolor{purple}{A program can have more than one heap, multiple heads for multiple requirements}
\item \textcolor{purple}{Additional heaps can be made with \textbf{HeapCreate}, which have a windows chosen Heap allocation type}
\item \textcolor{purple}{Allocation and Freeing is done with \textbf{HeapAlloc} and \textbf{HeapFree}}
\vspace{-3mm}
\end{itemize} 
\\
\hline
The goal with memory and the OS/Processes & 
The operating system protects against: \newline
\begin{itemize}
\item \textcolor{purple}{Access on OS memory}
\item \textcolor{purple}{Access on memory of other processes}
\end{itemize}
\, \newline
However, \textcolor{red}{it does NOT protect against:}\newline
\begin{itemize}
\item \textcolor{purple}{Wrong memory usage inside a process}
\vspace{-3mm}
\end{itemize}
\\
\hline 
No protection & 
The most basic implementation does not care about how a process accesses memory, it can do whatever it wants, and the problem with this is that, if a program accesses or even overwrites memory which it does not own, it might overwrite memory of another program, crashing said program with it!\newline
This means that potentiall a process can crash the OS by manipulating OS memory!\newline
Either intentionally or unintentionally.\newline
\textcolor{red}{This approach is not used in modern systems!}\\
\hline
Approach OS handles memory & 
\textcolor{orange}{Here you limit what the processor can do, this means that the operating system will have full control over what memory each process will be able to call/use.}\newline
\textcolor{red}{As expected, this approach would be really slow, which is why it is no longer used for modern systems (other than embedded perhaps)}
\\
\hline
Privilege Levels & 
Processors have different privilege levels, \textbf{PL0, PL1, PL2, PL3}.\newline
\textcolor{orange}{These are the ring0 to ring3 levels that everyone is always talking about!}\newline
\includegraphics[scale=0.2]{2022-12-06-03:25:15.png}\\
\\
\hline
\end{tabular}
\end{table}
\pagebreak
\begin{table}[ht!]
\begin{tabular}{|m{0.2\linewidth}|m{0.755\linewidth}|}
\hline
Sys-Call & 
\textcolor{Orange}{This is the function that will be deposited in memory at startup, and will be called each time a program wants to interact with the operating system.}\newline
We have already used this in assembly with the syscall command!\newline
\begin{lstlisting}
mov rax, ; OS code to be executed
mox rdi, ; first argument
syscall

; this is nothing other than the following: 

mov rcx, rip    ; command counter of program
mov r11, rflags ; flags of program
; PL0 from now on 
mov rip, IA32_LSTAR ; OS handler
\end{lstlisting} 
\, \newline
example codes, 0 for red, 1 for write, 60 for exit, \textbf{this is variable on operating systems though!}\newline

\\
\hline
Approach Virtual Addresses & 
\vspace{2mm}
\begin{itemize}
\item \textcolor{purple}{Processes will not receive proper addresses, instead they receive \textbf{virtual addresses}}\newline
  This will then be converted to proper addresses by the \textbf{Memory Management Unit}
\item \textcolor{purple}{OS configures Memory Management Unit}
\item \textcolor{purple}{Memory Management Unit (MMU) checks for restrictions on memory}\newline
  Is this process allowed to access this memory? Read? Write?
\end{itemize} 
\, \newline
\includegraphics[scale=0.3]{2022-12-06-03:36:53.png}\includegraphics[scale=0.3]{2022-12-06-03:39:13.png}\newline
\textcolor{orange}{The mapping of real addresses to virtual addresses are a \textbf{black box} to processes, it is basically impossible to "guess" a physical address and read/write to it!}\newline
\textcolor{purple}{The processor can either receive \textbf{a page table, a page directory, or even a higher variant!}}\newline
\textcolor{red}{This is the approach that is used on modern systems!}\\
\hline
Valid Access & 
\minipg{
\begin{itemize}
\item \textcolor{black}{Process wants to access a valid address}
\item \textcolor{black}{MMU finds mapping in mapping table}
\item \textcolor{black}{MMU puts real address on memory bus}
\item \textcolor{black}{processor reads/writes data from and to memory bus}
\end{itemize}
}{
\includegraphics[scale=0.4]{2022-12-06-03:43:32.png}
}[0.4,0.4]\\
\hline
Invalid Access &
\minipg{
\begin{itemize}
\item \textcolor{black}{Process wants to access an invalid address}
\item \textcolor{black}{MMU tries to read mapping but it fails -> invalid}
\item \textcolor{black}{MMU signals \textbf{fault interrupt}}
\item \textcolor{black}{CPU calls OS-Interrupt Handler }
\item OS takes charge:\newline
  For example kill process as answer...
\end{itemize}
}{
\includegraphics[scale=0.4]{2022-12-06-03:43:38.png}
}[0.4,0.4]\\
\hline
Swap & 
In linux we need swap in order to store our memory on our storage (SSD/HDD), this makes it possible to use more RAM than we actually have by storing things we currently do not necessarily need on our storage intead.\newline
This is also how we can achieve "sleep" mode, where we do not have any RAM loaded, instead it is stored on our storage at shutdown.\newline
\minipg{
\includegraphics[scale=0.4]{2022-12-06-03:50:16.png} 
}{
Note that the OS handles when this happens, a process will \emph{usually} not notice anything!\newline
Effects:\newline
\begin{itemize}
\item \textcolor{purple}{More Memory per Process}
\item \textcolor{purple}{Process can use entire memory}
\item \textcolor{purple}{No regard for other processes need to be given}
\item \textcolor{purple}{Absolut addresses}
\end{itemize} 
Please use this "entire memory" thing carefully, as paging will be a performance hit!!
}[0.35,0.4]\\
\hline
\end{tabular}
\end{table}
\pagebreak
\begin{table}[ht!]
\begin{tabular}{|m{0.2\linewidth}|m{0.755\linewidth}|}
\hline
Page based Virtual Memory & 
\minipg{
\begin{itemize}
\item \textcolor{black}{Page}\newline
  typically 4KB\newline
  Page is always one unit
\item \textcolor{black}{Memory consists of Page Frames}\newline
  each Pageframe can hold one page\newline
  Start address: multiple of pagesize\newline
  Page Frame Number = Sartaddress of Pageframe without Offset-Bit
\item \textcolor{black}{Example with 32 Bit System}\newline
  Memory address = AB789000
  Page Frame Number = AB789
\end{itemize} 
}{ 
\includegraphics[scale=0.4]{2022-12-06-04:13:15.png}
}[0.4,0.4]\newline
\begin{itemize}
  \item \textcolor{purple}{Virtual Address space consist of pages}\newline
    Page represents data
\item \textcolor{purple}{Per Process one Virtual Address Space}
\item \textcolor{purple}{Per Process one Page-Table (Mapping)}
\vspace{-3mm}
\end{itemize}
\includegraphics[scale=0.4]{2022-12-06-04:16:25.png}\newline
Both process A and B have their own space A1 to Am and B1 to Bn, and each has their own mapping inside the MMU, this leads to the effect, that the pages can be shuffled, without losing any functionality, as the pages are mapped!\newline
\includegraphics[scale=0.4]{2022-12-06-04:19:35.png}\newline
\textcolor{orange}{As seen here, pages can be in memory or in storage, meaning that it doesn't matter other than performance wise!}\newline 
\begin{itemize}
\item \textcolor{purple}{OS decides where page is stored}
\item \textcolor{purple}{MMU only knows memory, no storage}
\item \textcolor{purple}{MMU can only detect missing pages}\newline
  Page in storage, or doesn't exist.\newline
  \textcolor{red}{This means the OS needs to retrieve pages when not in memory!!}
\vspace{-3mm}
\end{itemize} 
\\
\hline
Page Table & 
\vspace{2mm}
\begin{itemize}
\item \textcolor{purple}{Translates the virtual addresses to real addresses for the MMU}
\item \textcolor{purple}{Is configured by the OS}
\item \textcolor{purple}{The MMU needs the following from the page table:}\newline
  \begin{itemize}
  \item \textcolor{black}{In which Page-Frame is the page?}
  \item \textcolor{black}{Is the address of the page valid?}
  \end{itemize} 
\item \textcolor{purple}{The OS needs the following from the page table:}\newline
  \begin{itemize}
  \item \textcolor{black}{Is the page in memory or in storage?}
  \item \textcolor{black}{Will the page even be used?}
  \item \textcolor{black}{Was the page used since its creation?}
  \end{itemize} 
\end{itemize}
\textcolor{red}{Multiple Implementation Variants}
\begin{itemize}
\item \textcolor{orange}{Single-Level}
\item \textcolor{orange}{Multi-Level}
\item \textcolor{orange}{Inverted}
\item \textcolor{orange}{Hashtable}
\vspace{-3mm}
\end{itemize} 
\\
\hline
Page Fault & 
\textcolor{red}{A page fault happens when a process tries to access a page that doesn't exist in the virtual memory mapping, meaning that the mapping needs to be created.}
\\
\hline
\end{tabular}
\end{table}
\pagebreak
\begin{table}[ht!]
\begin{tabular}{|m{0.2\linewidth}|m{0.755\linewidth}|}
\hline
Page-Table Single-Level & 
\begin{itemize}
\item \textcolor{purple}{Array with an entry per page}\newline
\item \textcolor{purple}{\textbf{Always allocates the entire table!}}\newline
  This means that with 1024 possible Pages inside a table, each page is allocated!\newline
  1024 * 4KB = 1M
\item \textcolor{purple}{very fast Lookup!}\newline
  Index = Page Number
\end{itemize} 
\includegraphics[scale=0.4]{2022-12-06-04:32:58.png}\newline 
\includegraphics[scale=0.4]{2022-12-06-04:34:46.png}\newline
Downsides: \newline
\begin{itemize}
\item \textcolor{red}{Size of page-tables can be extremely big!}\newline
  For each possible page \textbf{one entry}\newline
  OS/MMU can limit the size of the pagetable
\item \textcolor{red}{Page size is not dependent on usage, same size!}
\vspace{-3mm}
\end{itemize}\\ 
\hline
Two-Level Page-Table & 
This works very much like the Two-Way cache where we have to tables, if the first table -> \textbf{Page Directory} already doesn't find an associated table \textbf{Page Table} for this process, then we don't need to search further! \newline
Remember each process will only have 1 page table!\newline
\includegraphics[scale=0.4]{2022-12-06-04:41:50.png}\newline
Just like with the cache we have \textbf{an offset, here this is the \emph{last 12 bits.}}\newline
Then we split the rest in 2, note that the results are strange since it is hex.\newline
\textbf{Status bits define is the table is used or not!}\newline
\includegraphics[scale=0.4]{2022-12-06-04:41:59.png} 
\, \newline
\textcolor{red}{IMPORTANT: With \textbf{Page Directories or higher, it does not allocate memory if the page table is unused!}
Also, \textbf{ALL entries, no matter if page table or page directory are 32bit!, even though many of these bits aren't used in the page table or directory!}}\newline
\textcolor{orange}{Sometimes the second "table" is also called \textbf{Second-Level-Page-Table (SLPT)}}\\
\hline
\end{tabular} 
\end{table}
\pagebreak 
\begin{table}[ht!]
\begin{tabular}{|m{0.2\linewidth}|m{0.755\linewidth}|}
\hline
Two-Level Page-Table Implementation in 32bit &
\vspace{2mm}
\begin{itemize}
\item \textcolor{purple}{Directory Index = 10 Bit}
\item \textcolor{purple}{Page Table Index = 10 Bit}
\item \textcolor{purple}{Offset = 12 Bit (lowest 2 bits)}
\item \textcolor{purple}{Entry in Directory or Table each 32-bit}
\item \textcolor{purple}{1024 Page Tables with 1024 pages each}
\item \textcolor{purple}{Directory size = 4kB}
\item \textcolor{purple}{Table size = 4kB}
\item \textcolor{purple}{Page size = 4kB}
\item \textcolor{purple}{Mechanism for allocating and reloading for tables and pages}
\vspace{-3mm}
\end{itemize} 
\\
\hline
Multi-Level Page-Table & 
This is also the same as the multi-way on caches, currently the maximum amount of levels is 5!\newline
This is because right now, noone will need more than 5 levels which is more ram than you could possibly have.\newline
They thought the same for 256TB on level 4, but that has been reached!\newline
\includegraphics[scale=0.4]{2022-12-06-04:46:09.png} 
\begin{itemize}
\item \textcolor{purple}{Size of 4kB per Page stays the same!} 
\item \textcolor{purple}{Entries are 64bit long -> hence the 64 bit system architecture}
\item \textcolor{purple}{Level 3 = 512 GB max}
\item \textcolor{purple}{Level 4 = 256 TB max}
\vspace{-3mm}
\end{itemize}\\ 
\hline
Translation Lookaside Buffer & 
This is based on the locality principle, meaning that most pages are used rarely, and only a few pages are used often, these pages can then be "cached" on a lower L cache!\newline
\textcolor{orange}{Here we only cache the mappings, not the data! As this is only a lookup buffer!}\newline
Here an example of i7 skylake\newline
\includegraphics[scale=0.4]{2022-12-06-04:49:25.png}\\
\hline
Inverted Page Table & 
\textcolor{red}{Not used in practice.}\newline
Instead of pages we store the frames, since the page tables can be very big. So we use the frames instead, however, the search takes too long....\newline
\includegraphics[scale=0.4]{2022-12-06-04:49:54.png}\\
\hline
\end{tabular}
\end{table}
\pagebreak 
\begin{table}[ht!]
\begin{tabular}{|m{0.2\linewidth}|m{0.755\linewidth}|}
\hline
Hashed Page Table & 
Instead of using an index, we use a hash instead.\newline
Benefit of this is that we need less space, but it might get collisions, forcing us to use linked lists, etc.\newline
\textcolor{red}{Nobody does this however.}\newline
\includegraphics[scale=0.4]{2022-12-06-04:50:00.png}\\
\hline
The reason for MMU & 
\minipg{
\begin{itemize}
\item \textcolor{purple}{Only MMU can access memory requests}
\item \textcolor{purple}{CPU no longer puts addresses directly to memory bus}
\item \textcolor{purple}{MMU takes over creation of real addresses}
\end{itemize} 
}{
\includegraphics[scale=0.4]{2022-12-06-04:24:32.png} 
}[0.34,0.4] \newline
\minipg{
\begin{itemize}
\item \textcolor{purple}{MMU receives virtual address from CPU}\newline
  \begin{itemize}
  \item \textcolor{black}{Virtual addresses are CPU specific}
  \item \textcolor{black}{OS must set pointer on page-table on process change}
  \end{itemize} 
\item \textcolor{purple}{MMU translates each virtual address based on the base register}
\item \textcolor{purple}{MMU has its own cache -> Translation lookup buffer}
\end{itemize} 
}{
\includegraphics[scale=0.4]{2022-12-06-05:34:14.png}\newline
}[0.4,0.4] \newline 
\begin{itemize}
\item \textcolor{purple}{Virtual address is split into:}\newline
  \begin{itemize}
  \item \textcolor{black}{Offset: 12 lowest bits for index like with cache}
  \item \textcolor{black}{Page Number: all other bits}
  \end{itemize} 
\item \textcolor{purple}{Only the page number will be translated by the MMU}
\item \textcolor{purple}{Offset stays the same}
\end{itemize}
\includegraphics[scale=0.4]{2022-12-06-05:34:21.png} 
\includegraphics[scale=0.4]{2022-12-06-05:34:27.png}\\
\hline
Example for translating an address from virtual to read with page directories and page tables &
\vspace{2mm}
\includegraphics[scale=0.3]{2022-12-09-03:30:07.png}\\
\hline
\end{tabular}
\end{table}
\pagebreak
\begin{table}[ht!]
\begin{tabular}{|m{0.2\linewidth}|m{0.755\linewidth}|}
\hline
Accessed and Dirty Bit &
\textcolor{purple}{This case considers that the page is present -> status bit is 1}\newline
\textcolor{red}{On each \textbf{access the MMU sets the Access-Bit -> A-Bit}, and on each \textbf{write, it writes the Dirty-Bit -> D-Bit}}\newline
\includegraphics[scale=0.4]{2022-12-13-03:22:16.png}
\, \newline
\textcolor{orange}{\textbf{Only the OS can reset either of those 2 bits!}} 
Note that, the MMU doesn't use these bits and these bits are the 12 offset bits!\\
\hline
Status bit 0 & 
When the page is not in the virtual memory, the MMU will throw an \textbf{interrupt}, the OS can then check and decide what will happen -> is the access valid?.\newline
\textcolor{red}{Should the access not be valid, then a \textbf{segmentation fault will be thrown!}\newline
Should the access be valid, then it will try to load the page into memory, should no space be available, then it will try to throw a currently unused one out.}\newline
The OS will then tell the MMU to recheck the virtual memory if the access was valid, meaning the process will finally get the page that it wanted.\newline
\includegraphics[scale=0.4]{2022-12-13-03:26:16.png}\\
\hline
Threshing & 
This is the case when the CPU will be forced to load pages from storage and store old ones repeatedly due to lack of free memory.\newline
\textbf{Should this happen, then the system will no longer be able to do actual work, as it is busy loading pages instead.}\newline
\includegraphics[scale=0.4]{2022-12-13-03:31:53.png}
\, \newline
The general solutions to this are: \newline
\begin{itemize}
\item \textcolor{black}{More RAM, kekw get rich fuckboi}
\item \textcolor{black}{Restriction on process count}
\item \textcolor{black}{Better paging strategies}
\vspace{-3mm}
\end{itemize} \\
\hline
Paging Strategies & 
We differentiate 3 parts of paging strategies, namely:\newline
\begin{itemize}
\item \textcolor{purple}{Fetching Policies}\newline
  load page from storage, when and how many at once?
\item \textcolor{purple}{Cleaning Policies}\newline
  when to store page on storage
\item \textcolor{purple}{Page Replacement Policies}\newline
  replace old page with new one in memory, which ones?
\vspace{-3mm}
\end{itemize} 
\\
\hline
Fetching Policies & 
\vspace{2mm}
\begin{itemize}
\item \textcolor{purple}{Demand Paging}\newline
  \begin{itemize}
  \item \textcolor{black}{Load on Demand}\newline
    \textcolor{orange}{Requires an interrupt each time}
  \item \textcolor{green}{Benefit: Minimal Effort}
  \item \textcolor{red}{Negative: Long Loading time}\newline
    each Page-Fault causes the process to wait
  \end{itemize} 
\item \textcolor{purple}{Prepaging}
  \begin{itemize}
  \item \textcolor{black}{Pages are loaded in early}
  \item \textcolor{black}{System tries to guess which pages are needed}\newline
    Via system analyses and tracking of processes
  \item \textcolor{black}{Not used in actual implementations}
  \end{itemize} 
\item \textcolor{purple}{Demand Paging with Prepaging}\newline
  \begin{itemize}
  \item \textcolor{black}{Like Demand Paging, but neighbours are loaded as well}\newline
    based on locality principle, loaded in clusters -> 4-8 Pages
  \item \textcolor{green}{Benefit: less Page-Faults, Block transfer -> faster when storing to storage}
  \item \textcolor{red}{Negative: Potentially unused pages are loaded}
  \item \textcolor{black}{Most used in real implementations}
  \end{itemize} 
\item \textcolor{purple}{Increasing based on Heuristics}\newline
\vspace{-3mm}
\end{itemize} 
\, \newline
An example for \textbf{Demand Paging with Prepaging}\newline
\includegraphics[scale=0.4]{2022-12-13-03:41:54.png}\\
\hline
\end{tabular}
\end{table}
\begin{table}[ht!]
\begin{tabular}{|m{0.2\linewidth}|m{0.755\linewidth}|}
\hline
Cleaning Policies &
\vspace{2mm}
\begin{itemize}
\item \textcolor{purple}{Demand Cleaning}\newline
  \begin{itemize}
  \item \textcolor{black}{Cleaning on Demand}\newline
  Page will be stored on storage if it will be used again
  \item \textcolor{green}{Benefit: Minimal Effort}\newline
    Page only stored when necessary
  \item \textcolor{red}{Negative: Longer Loading Time}\newline
  Process needs to wait for old page to be written
  \end{itemize} 
\item \textcolor{purple}{PreCleaning or Page Buffering}\newline
  \begin{itemize}
  \item \textcolor{black}{Write on Guess}\newline
    Just like PrePaging, the system will write based on its information
  \item \textcolor{green}{Benefit: Reduced Loading Time}\newline
    Old page doesn't need to be written (the one to be \textbf{updated})\newline
  \item \textcolor{red}{Negative: More Effort}\newline
    Pages can be changed again after write...
  \end{itemize} 
\vspace{-3mm}
\end{itemize}
\, \newline
An example with \textbf{Page Buffering, a variant of Page Cleaning}\newline
\includegraphics[scale=0.4]{2022-12-13-03:46:39.png}\newline 
The OS handles 2 lists, one modified and one unmodified, OS puts pages to either list in intervals.\newline
When Page is in modified list, it has dirty bit written. OS then writes this page to storage, removes the dirty bit and puts the page in the unmodified list.\\
\hline
Replacement Policies & 
\textcolor{red}{This is used when the memory space is not big enough and an old page needs to be replaced! \textbf{No thrashing yet, this would be continuous replacement}}.\newline
\begin{itemize}
\item \textcolor{purple}{FIFO}
\item \textcolor{purple}{Second Chance}
\item \textcolor{purple}{Clock}
\item \textcolor{purple}{Least Recently Used}
\item \textcolor{purple}{Least Frequently Used}
\item \textcolor{purple}{Working Set}
\item \textcolor{purple}{Working Set with Clock}
\vspace{-3mm}
\end{itemize}
\, \newline
In general this is \textbf{a massive performance factor!!} And it is an active field of research.\\
\hline
Basics for Replacement Strategies &
\vspace{2mm}
\begin{itemize}
\item \textcolor{purple}{MMU sets \textbf{Status Bits}, OS resets them}
\item \textcolor{purple}{Dirty Bit}\newline
\begin{itemize}
  \item \textcolor{black}{Meaning: Page on memory is different to page on storage}
\item \textcolor{black}{MMU sets dirty bit on each write Operation}
\item \textcolor{black}{OS should only reset it, when page is actually written to storage}
\end{itemize}
\item \textcolor{purple}{Access Bit}\newline
\begin{itemize}
\item \textcolor{black}{Meaning: Page has been used recently in the process}
\item \textcolor{black}{MMU sets access bit on each read or write Operation}
\item \textcolor{black}{OS should reset this based on an interval}
\end{itemize} 
\vspace{-3mm}
\end{itemize}
\, \newline
List of Dirty and Access Bit combinations:\newline
\begin{itemize}
\item \textcolor{black}{A=1, D=0} -> recently read
\item \textcolor{black}{A=1, D=1} -> recently written
\item \textcolor{black}{A=0, D=1} -> written a while ago
\item \textcolor{black}{A=0, D=0} -> there was no access for a while
\vspace{-3mm}
\end{itemize}
\, \newline
\textcolor{OliveGreen}{The OS prefers to replace "clean" Pages with both D=0 and A=0 as it is not used.}\\
\hline
Best (not possible) Variant & 
The best variant is the one that will replace the page that will be accessed last. Problem, this is basically not possible to implement as we do not know the future, we can only guess it.\newline 
\textcolor{red}{This is simply used as a best case, \textbf{since there is no other algorithm that will be faster than this!}}\\
\hline
FIFO & 
The idea is simply, just replace the oldest page.\newline
\begin{itemize}
\item \textcolor{green}{No status bits necessary}
\item \textcolor{green}{Easy to implement}
\item \textcolor{black}{Linked List style}
\item \textcolor{red}{Old pages will be deleted and might get reloaded immediately as a process needs it}
\item \textcolor{red}{\textbf{Beladys Anomaly} -> bigger Memory can lead to more page faults}
\end{itemize} 
\includegraphics[scale=0.4]{2022-12-13-04:18:45.png}
\\
\hline
\end{tabular}
\end{table}
\pagebreak
\begin{table}[ht!]
\begin{tabular}{|m{0.2\linewidth}|m{0.755\linewidth}|}
\hline
Second Chance & 
\textbf{Extension of FIFO, it checks A-Bit of oldest page.}\newline
If the A-Bit is 0, the page is \textbf{old and is not used} -> deleted\newline
If the A-Bit is 1, the page is \textbf{old but used} -> page is kept and pushed to end of list, checks next first page instead.\newline
\includegraphics[scale=0.4]{2022-12-13-04:23:54.png}\\
\hline
Clock & 
\textbf{Efficient implementation of Second Chance.}\newline
\textcolor{orange}{Linked List in Clock graph, Elements aren't moved, only pointer is moved}\newline
\includegraphics[scale=0.4]{2022-12-13-04:25:15.png}\\
\hline
Least Recently Used & 
\begin{itemize}
\item \textcolor{purple}{Replace the page not used for the longest time}\newline
  \begin{itemize}
  \item \textcolor{black}{Time is noted on each MMU access}
  \item \textcolor{black}{Page with oldest time is replaced}
  \end{itemize}  
\item \textcolor{purple}{Requires a lot of effort in Hardware}\newline
  \begin{itemize}
  \item \textcolor{black}{Page entries are bigger -> page tables are bigger}
  \item \textcolor{black}{Time on access needs to be noted}
  \end{itemize}  
\item \textcolor{red}{Most MMUs can't use this variant}
\vspace{-3mm}
\end{itemize} 
\includegraphics[scale=0.4]{2022-12-13-04:25:42.png}\\
\hline
Interrupt Idea for \textbf{certain variants} & 
With the last variant we had the problem that not all MMUs can generate a timestamp, but guess what definitely can generate one, the OS.\newline
The idea is that the OS will create a timestamp each time there is an access to a page.\newline
\textcolor{OliveGreen}{Benefit: No fancy MMU needed, interval can be defined by the OS dynamically}\newline
\textcolor{red}{Negative: Big interval is inaccurate, small interval creates more overhead.\newline
Timestamp only shows that it was accessed within this timeframe, not how many times or when exactly}\\
\hline
Not Frequently Used & 
This uses the \textbf{Timer Interrupt} strategy with a counter to also check \textbf{how many times a page was used}.\newline
The downside is that you need an \textbf{additional counter table which is created for each page table.}\newline
If page is not used within an interval counter is decremented, if it is used incremented per access.\newline
\includegraphics[scale=0.4]{2022-12-13-04:28:40.png}\newline 
\textcolor{red}{Problem: long pages that have not been used recently can still linger for a long time if they have a huge counter... This means it will take a long time for these pages to be cleaned up.}
\\
\hline
Not Frequently Used with Aging & 
As the name says, this solves the issue with aging, as the counter \textbf{shifted to the right each interval.}\newline
\textbf{Note, the counter is not a real counter anymore, only the Access bit, but it does offer a number, namely used within timeframe x at least once}\newline
\textcolor{red}{(Counter >> 1) + (A << n)} A is the access bit, n is the interval -> 0 to \(\infty\)\newline
\includegraphics[scale=0.4]{2022-12-13-04:37:48.png}\\
\hline
\end{tabular}
\end{table}
\pagebreak
\begin{table}[ht!]
\begin{tabular}{|m{0.2\linewidth}|m{0.755\linewidth}|}
\hline
Working Set & 
This also uses a timer, but \textbf{instead of using a timer interrupt, it uses the page-fault interrupt instead}.\newline
If the A-bit of a page at this time is 1, then set A to 0 and timestamp to now.\newline
If the A-bit of a page at this time is 0:\newline
\textcolor{orange}{T is the interval chosen, one timestamp per page Table}\newline
\begin{itemize}
\item \textcolor{black}{if time now - last timestamp t < T} \textcolor{red}{Page is in the working set and stays}
\item \textcolor{black}{if time now - last timestamp t > T}\textcolor{red}{Page is not in the working set and can be cleaned}
\item \textcolor{black}{Should no page be found to clean, oldest page is removed (clean page prefered)}
\end{itemize}
\, \newline
\includegraphics[scale=0.4]{2022-12-13-04:47:06.png}\\
\hline
WSClock & 
This is the same as working set, only that this \textbf{has a proper clock, and therefore doesn't need to save timestamps for each timetable, it can be checked at any time. -> iterate over clock at fault-interrupt}\newline
\includegraphics[scale=0.4]{2022-12-13-04:47:27.png}\\
\hline

\hline

\hline

\hline

\hline

\hline

\hline

\hline

\hline

\hline

\hline

\hline

\hline
\end{tabular}
\end{table}
\pagebreak
\begin{table}[h!]
\section{Assembly}
\begin{tabular}{|m{0,2\linewidth}|m{0.755\linewidth}|}
\hline
assembler \newline 
assembly & This is the "compiler" of assembly. Be aware this is \textbf{platform specific!!} we will use \emph{Netwide Assembler NASM}\newline This is a programming language.\\
\hline
Assembler converts instructions\newline directly into binary. & db 48 | Byte 48d \newline
db 0x35, 0h21, 049h | Bytes 35h , 21h , 49h \newline
db ’a’ | with ASCII-Code of a = 61h \(\equiv\) db 0x61 \newline
db ’Hello’ | ASCII-Codes of H, e, l, l and o \(\equiv\) db 0x48, 0x61, 0x6c, 0x6c, 0x6f\newline
Word       | dw 0x2135 | \(\equiv\) db 0x35, 0x21\newline
Doubleword | dd 0x2135 | \(\equiv\) db 0x35, 0x21, 0x00, 0x00, \newline 
Quadword   | dq 0x2135 | \(\equiv\) db 0x35, 0x21, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00 \\
\hline
Numbers in assembly & 200 | 0200d | 0d200 | 0c8h | \$0c8h | 0xc8 | 0hc8 \newline
11001000b | 1100\_1000b | 1100\_1000y | 0b1100\_1000 | 0y1100\_1000
\\
\hline
Pointers in Assembly & \vspace{2mm}\includegraphics[scale=0.2]{2022-09-27-04:12:53.png} \newline
1AF8 now has a pointer in another place. \newline
\includegraphics[scale=0.2]{2022-09-27-04:17:16.png}\newline
This would also produce the same result. Aka you can use labels before the operation.\newline
\includegraphics[scale=0.2]{2022-09-27-04:24:38.png}\\
\hline
A simple length calculation in assembly & \vspace{2mm} \includegraphics[scale=0.2]{2022-09-27-04:27:52.png}\newline 
First we define a label called length, but we can't calculate this yet as my\_text and after\_my\_text aren't defined yet.\newline
So we continue to the next line, here we write BSys 1?! and set the value of my\_text to 08 00 00 00 00 00 00.\newline
Then we define after\_my\_text with the value of the offset at this point, which is 0F 00 00 00 00 00 00 00.\newline
At last the length will have the value of 08 00 00 00 00 00 00 00, which is the length of BSys 1?!.\\
\hline
\textbf{\emph{Flat-Form Binaries vs Object-files}} & \textcolor{red}{The first is a simple binary of pure binary. Aka Machine-Code.}\newline
\textcolor{blue}{The second is the linked version with a symboltable to define labels.}\\
\hline
\textbf{\emph{Generate Object-file}} & \textbf{nasm -f elf64 prog.asm -o prog.o}\\
\hline
\textbf{\emph{Analyze Object-file}} & \textbf{objdump -t -d - Mintel prog.o}\newline
-t show symboltable \newline
-d disassemble\newline
-Mintel dissasemble code in intel format, aka show NASM format instead of GCC.\\
\hline
Assembly dumps in action & \vspace{2mm} \includegraphics[scale=0.2]{2022-09-27-04:45:55.png} \includegraphics[scale=0.2]{2022-09-27-04:46:02.png}\newline
write 2 bytes aka a word to file. offset is now at 16, or 10 in hex.\newline
Now we use label w, which is at offset 10h, then we write 0x12345678 size 8h.\newline
label x, offset 18h, write 0xCAFEFACE size 8h.\newline
label y, offset 20h, write z, \textbf{\emph{but this is empty until compiled!}}
\\
\hline
\textbf{mov Target/Sink, Source} & 
\vspace{2mm}
\begin{itemize}
  \item copy from source into target
  \item after execution of operations, the source and target/sink have the same value
  \item \emph{\textbf{Target <- Source}}
\end{itemize}
Here an example: \newline
mov rax, eax \t --> move register to register (no memory access) \newline
mov rax, 0x4000 \t --> move constant into register (no memory access)\newline
mov rax, [eax] \t --> move memory address of value eax into rax (memory access!)\\
\hline
\textbf{mov rules} &
\vspace{2mm}
\begin{itemize}
  \item \emph{move eax, ebx} | move 32 bit into 32 bit // ok
  \item \emph{move eax, rbx} | move 64 bit into 32 bit // ERROR!
  \item mov [0x8000], rax | put content of memory \(8000_h\) ... \(8007_h\) to the content of rax
  \item mov [0x8000], 5 | put content of memory \(8000_h\) ... \(8007_h\) to 5
  \item \textbf{HOWEVER, you can't move from memory to memory!}
  \item \textcolor{red}{mov [0x8000], [0x9000] ERROR!!!!!}
  \vspace{-3mm}
\end{itemize}\\
\hline
\end{tabular}
\end{table}
\pagebreak
\begin{table}[h!]
\begin{tabular}{|m{0,2\linewidth}|m{0.755\linewidth}|}
\hline
Operand size with memory & 
\vspace{2mm}
\begin{itemize}
  \item 8 bit: mov al, [0x8000] | copy content of 1 byte to al
  \item 16 bit: mov ax, [0x8000] | copy content of 2 bytes to ax
  \item 32 bit: mov eax, [0x8000] | copy content of 4 bytes to eax
  \item 64 bit: mov rax, [0x8000] | copy content of 8 bytes to rax \newline
  \textcolor{red}{assembly copys as much as it can into the operand.}
  \vspace{-3mm}
\end{itemize}\\
\hline 
\textbf{\textcolor{teal}{Displacement and Base}}&\minipg{
\pic{2022-10-04-04:29:18.png}\newline
\textcolor{red}{\textbf{Displacement is the use of an address directly -> [0x8000]}}}
{\pic{2022-10-04-04:29:27.png}\newline
\textcolor{green}{\textbf{Base is the use of an address with a variable -> [rbx]}}}[0.4,0.4]\\
\hline
\textbf{\textcolor{teal}{Scaled Index}} &
[i * s]
\begin{itemize}
  \item Index i is a register
  \item Scale s is the constant 1,2,4 or 8 -> bytes!
  \item The address is i * s
  \item The index is therefore scaled
\end{itemize}
mov rcx, 0x1000 \newline
mov rax, [rcx * 8] // rcx multiplied by 8. Since rcs is 0x1000 -> 0x8000\newline
Or you can also write it like this:\newline
mov rbx , 0 x4000\newline
mov rcx , 0 x1000\newline
mov rax , [0 x2000 + rbx + rcx * 2]\newline
\\
\hline
\textbf{Hello World in assembly} &
\begin{lstlisting}
hello: db 'Henlo Birb' ;db something -> write your text
hello_length: equ $ - hello ;hello_length is equal to the current pointer minus hello

global _start         ; specifies the scope of a variable
_start:               ; like main in cpp
mov rax, 0x1          ; move system write instruction into register -> write instruction is 1
mov rdi, 0x1          ; specifies to write to the IO register 
mov rsi, hello        ; move text into write register
mov rdx, hello_length ; move write pointer to before rsi
syscall               ; call the os to do something

mov rax, 60           ; move system exit instruction into register -> 60
mov rdi, 0            ; ? exit code for string operation?
syscall               ; call the os to do something
\end{lstlisting}\\
\hline
\textbf{Instructions} & 
\vspace{2mm}\large
\begin{itemize}
\item mov rax, 1 \textcolor{teal}{//move the value 1 into rax, keep in mind that mov can hold other operations!}
\item equ rax, 1+1 \textcolor{teal}{//arithmic operation}
\item add z,   q  \textcolor{teal}{// z + q} 
\item sub z,   q  \textcolor{teal}{// z - q}
\item adc z,   q  \textcolor{teal}{// z + q + c (carry bit from previous calculation)}
\item sbb z,   q  \textcolor{teal}{// z - q - c (carry bit from previous calculation)}
\item neg z       \textcolor{teal}{// 0 - z ("zweierkomplement")}
\item inc z       \textcolor{teal}{// z++ }
\item dec z       \textcolor{teal}{// z-- }
\item mul z,      \textcolor{teal}{// multiply with implicit 2.operand }\newline
mul rbx -> RDX:RAX <-- RAX * RBX
\item imul z,   i  \textcolor{teal}{// signed equivalent for mul, z * i }
\item div z,      \textcolor{teal}{// divide with implicit 2.operand}\newline
div rbx  \newline
d = RDX:RAX\newline
RAX <-- RDX:RAX / RBX\newline
RDX <-- RDX:RAX mod RBX
\item shl z,   i  \textcolor{teal}{// z * \(2^i\)               --> shift}
\item shr z,   i  \textcolor{teal}{// z * \(2^{-i}\) z signed   --> shift}
\item sar z,   i  \textcolor{teal}{// z * \(2^{-i}\) z unsigned --> shift}
\item rol z,   i  \textcolor{teal}{// Left-Rotate i Bits }
\item ror z,   i  \textcolor{teal}{// Right-Rotate i Bits }
\end{itemize}
\, \newline
\textcolor{teal}{cmp: This instruction essentially does the same as sub rax, rbs, however,\newline
the difference is that sub will overwrite the rax value, cmp will not!\newline
\textbf{cmp will only set the flags!}}\newline
\\
\hline
NAND in Assembly & 
\begin{lstlisting}
mov rax,  [x] ; rax <- x
mov rbx,  [y] ; rbx <- y
and rax,  rbx ; rax <- x AND y
not rax       ; rax <- NOT ( x AND y )
mov [z], rax  ; z   <- NOT ( x AND y )
\end{lstlisting}\\
\hline
Size in Assembly & 
\textcolor{orange}{With certain instructions, the size can't be derived\newline
here we need to specify the size!}\newline
\begin{lstlisting}
not word [myvar] ; the word being the size
\end{lstlisting}\\
\hline
\end{tabular}
\end{table}
\pagebreak
\begin{table}[h!]
\section{Linker}
\begin{tabular}{|m{0,2\linewidth}|m{0.755\linewidth}|}
\hline
Movation & 
\vspace{2mm}
\begin{itemize}
  \item translate files
  \item \textbf{translate iteratively, only translate those that have changed!}
  \item \textbf{distribute development to many people!}
  \item \textbf{version control}
\vspace{-3mm}
\end{itemize}\\
\hline
Unlinked files in C C++ and assembly & \textcolor{red}{The UND is means that there is a not yet linked symbol!}\newline 
\pic{2022-10-04-04:41:27.png}\\
\hline
Partial Linking & 
\textbf{ld -r prog.o prog2.o -o prog3.o}  | This links our missing symbol from above!\newline
\pic{2022-10-04-04:44:56.png}\\
\hline
\textbf{Creation an executable} & 
\pic{2022-10-04-04:49:23.png}\newline
\begin{itemize}
  \item ld //the tool
  \item -e // flag for executable
  \item main // the entry point!
  \item my\_prog.o // the object file to use
  \item -o // outputflag
  \item my\_prog // the name of the executable to create
\vspace{-3mm}
\end{itemize}\\
\hline
\textbf{Syscall / End of a Program} & \minipg{ 
\begin{itemize}
  \item mov rax, 60 | \textbf{OS-Syscall exit code -> 60} |put 60 into rax
  \item rdi, 0 | \textbf{8 bit exit code} | exit code 0 aka successful
  \item syscall | \textcolor{red}{execute rax code -> exit!}
\vspace{-3mm}
\end{itemize}}
{\pic{2022-10-04-04:52:29.png}}[0.39,0.4]\\
\hline
\end{tabular}
\end{table}
\pagebreak
\begin{table}[ht!]
\section{C Toolchain}
\begin{tabular}{|m{0.977\linewidth}|}
\hline 
\minipg{
\textcolor{red}{The C Toolchain consists of:}\newline
\begin{itemize}
  \item \textcolor{teal}{C Preprocessor} 
  \item \textcolor{teal}{C Compiler} 
  \item \textcolor{teal}{Assembler} 
  \item \textcolor{teal}{Linker} 
\end{itemize}
}{
  C just like C++ has 3 parts:\newline
  \begin{itemize}
    \item \textcolor{teal}{Preprocessor} -> parts like \#include
    \item \textcolor{teal}{Base contructs} -> variables function etc inside one file and in the base language
    \item \textcolor{teal}{Standard libraries} -> additional function and types 
    \vspace{-3mm}
  \end{itemize}
}\\
\hline
\end{tabular}
\section{C Preprocessor}
\begin{tabular}{|m{0.2\linewidth}|m{0.755\linewidth}|}
\hline
1. Iteration & 
In the first iteration the preprocessor removes all comments from the code.\\
\hline
2. Iteration &
The preprocessor tokenizes the code, so the compiler has an easier time later on.\newline
\textcolor{teal}{Here are the possible tokens:}
\begin{itemize}
  \item \textcolor{teal}{Identifier}\newline
    starts with a-z or A-Z followed by letters, digits, or \_
  \item \textcolor{teal}{Preprocessor Number}\newline
    starts with a digit followed by digits, numbers, \_, ., or exponents
  \item \textcolor{teal}{String or Character literals}\newline
    String starts with ""\newline
    Character starts with ''\newline
    Escape character is \textbackslash
  \item \textcolor{teal}{Operations and punctuators}\newline
    \pic{2022-10-11-03:40:12.png}\newline
    \textcolor{orange}{The C preprocessor is greedy, it means that it will always take the biggest possible token}
  \item \textcolor{teal}{others}

\end{itemize}
\, \newline
\textcolor{orange}{The whitespaces, tabs and newlines seperate the tokens, however not all tokens need to be seperated, such as a+b.}\newline
\pic{2022-10-11-03:35:25.png}\\
\hline
3. Iteration & 
Here the C preprocessor simply \textbf{executes preprocessor directives} and \textbf{replaces macros} with code.\\
\hline
Function & Preprocessor handles such things as \#include \#define and more.\newline
They are simply used to put the code into one piece again, something that we humans are too dumb to do :P\\
\hline
\end{tabular}
\subsection{Preprocessor Commands:}
\begin{tabular}{|m{0.2\linewidth}|m{0.755\linewidth}|}
\hline
\#ifdef / \#ifndef \newline \#define \newline \#endif & These are used to check if things are already defined, or to define them. Either for checks to avoid double definition, or to check if debug is used -> ifdef DEBUG\\
\hline
Include differences & \#include <library> \textcolor{teal}{search in the system include directories!}\newline
\#include "library" \textcolor{teal}{search in the current working directory, \textbf{AND after that in the system includes}}\\
\hline
\#pragma once & This is used to automatically avoid double include statements. Aka if it is included already simply ignore any double includes. \\
\hline
\textbf{Cmake} & cmake -B build | this will define the directory to build in \newline cmake --build directory | this will build the system into this directory \newline cmake . | creates the CMakeFile and other files inside the specified director
\\
\hline
\textbf{Macros (simple object version)} & 
\#define XYZ 123 \newline
int x = XYZ compiles to int x = 123\newline 
\textcolor{orange}{Macros can't be a single character !}\\
\hline
\textbf{General Rule} & \emph{Only include what's necessary, don't just generalize includes to include everything!}\\
\hline
\end{tabular}
\section{C Compiler / Linker}
\begin{tabular}{|m{0.2\linewidth}|m{0.755\linewidth}|}
\hline
Commands &
\begin{itemize}
  \item gcc prog.c -o prog \textcolor{teal}{compile and link the prog.c with the ouput prog}
  \item gcc -c prog.c \textcolor{teal}{only compile the program -> prog.s as output}
  \item gcc -masm=intel -S prog.c \textcolor{teal}{only compile without assembling -> prog.o as output}
  \item gcc -E prog.c > prog.prep.c \textcolor{teal}{only run preprocessor commands -> prog.prep.c as output}
  \vspace{-3mm}
\end{itemize}\\
\hline
Function & 
\textcolor{orange}{\textbf{The compiler translates a pure c file (no preprocessor commands) to an assembly file}}\\
\hline
\end{tabular}
\end{table}
\begin{table}[ht!]
\begin{tabular}{|m{0.2\linewidth}|m{0.755\linewidth}|}
\hline
Translation example from C to Assembly &\pic{2022-10-11-04:26:03.png}\\
\hline
\textbf{\emph{Declaration}}
&
This only declares the variable, it does not have a predefined value -> undefined behavior!\newline
\begin{lstlisting}
exter int i;
extern char c;
\end{lstlisting}
\,\newline
\textcolor{red}{\textbf{PLEASE, note the \emph{extern} keyword}}\newline
\textcolor{orange}{This means that only a tag is declared, there is no memory allocation yet.\newline
Without extern the memory is allocated, this is as the extern expects the variable to be declared/defined somewhere else}\\
\hline
\textbf{\emph{Definition}}
&
This defines a variable with a set value.\newline
\begin{lstlisting}
int i = 5;
int a{5};
\end{lstlisting}
\\
\hline
\end{tabular}
\begin{tabular}{|m{0.2\linewidth}|m{0.3665\linewidth}|m{0.3665\linewidth}|}
\hline
Assembly vs C Declaration and Definition &
Assembly:\newline 
\begin{lstlisting}
my_var : dq 0 x4000
mov rax , [ my_var ]
\end{lstlisting}
\, \newline
C:\newline
\begin{lstlisting}
int my_var;
\end{lstlisting}
&
Assembly:\newline
\begin{lstlisting}
x : dd 15
\end{lstlisting}
\, \newline
C:\newline
\begin{lstlisting}
int x = 15;
\end{lstlisting}
\\
\hline
\end{tabular}
\begin{tabular}{|m{0.2\linewidth}|m{0.755\linewidth}|}
\hline
\textbf{static keyword} & 
\textcolor{red}{as there are no classes in C, the static keyword is used for something else\newline
This means that the variable can't be exported!!}\newline
\begin{lstlisting}
static int c = 5;
\end{lstlisting}
\, \newline
\pic{2022-10-11-11:12:14.png}\\
\hline
\textbf{Identifiers} & 
Identifiers are needed to format the output of \textcolor{teal}{printf} as a certain number/type.\newline
\begin{itemize}
\item \textcolor{teal}{sizeof(Integer) as signed decimal = \%d}
\item \textcolor{teal}{sizeof(Integer) as unsigned decimal = \%u}
\item \textcolor{teal}{sizeof(Integer) as hexadecimal = \%x or \%U}
\item \textcolor{teal}{sizeof(long) as signed decimal = \%li}
\item \textcolor{teal}{sizeof(long long) as signed decimal = \%lli}
\item \textcolor{teal}{sizeof(void *) as pointer (hexadecimal -> address) = \%p}
\item \textcolor{teal}{sizeof(cahr *) as pointer (null terminated string) = \%s}
\item \textcolor{teal}{sizeof(double) as floating point decimal = \%f}
\item \textcolor{teal}{}
\item \textcolor{teal}{}
\vspace{-3mm}
\end{itemize}\\
\hline
\end{tabular}
\subsection{Objects in C}
\begin{tabular}{|m{0.977\linewidth}|}
\hline
\textcolor{orange}{\textbf{C is not object oriented, objects are not the same as in C++}\newline
When we talk about objects in C, then we talk about any variable instance, for example an integer is an object.}\newline
\textcolor{teal}{Each object has some sort of value, for integer this is a number.}\newline
\textcolor{blue}{\textbf{In the end, an object is just an allocation of memory!}}\newline
The reason for this is that we once thought we might have a different way of storing things at some point\newline
Turns out this was wrong and we still use memory for storing everything.\\
\hline
\end{tabular}
\begin{tabular}{|m{0.2\linewidth}|m{0.755\linewidth}|}
\hline
Operations in C & 
\textcolor{orange}{C will enforce operand type equality, this means that it will try to cast to get this,\newline
or it will simply not work.}\\
\hline
Existence of types & 
Just like c++, after you compile C, it will no longer have types, just like assembly.\newline
Types only exist to make it easier to program.\\
\hline
\textbf{sizeof(T)}&
\textcolor{orange}{Each type has a size that you can check, however, this is compiler, OS and even architecture dependent!\newline This can therefore not be taken for granted.}\newline
\textcolor{red}{However, this is one of the reasons that C and C++ is so fast!}\\
\hline
\textbf{\textcolor{red}{minimum} size of variables}&
\vspace{2mm}
\begin{itemize}
  \item \textcolor{teal}{signed char} \(\geq\) 8 Bit
  \item \textcolor{teal}{short int} \(\geq\) 16 Bit
  \item \textcolor{teal}{int} \(\geq\) 16 Bit \(\geq\) short
  \item \textcolor{teal}{long int} \(\geq\) 32 Bit
  \item \textcolor{teal}{long long int} \(\geq\) 64 Bit
  \item \textcolor{teal}{void} no real value!
  \vspace{-3mm}
\end{itemize}\\
\hline
\end{tabular}
\end{table}
\pagebreak 
\begin{table}[ht!]
\begin{tabular}{|m{0.2\linewidth}|m{0.755\linewidth}|}
\hline
signed or unsigned & 
\textcolor{orange}{Just like in c++ you can write unsigned to get the max possible positive number.\newline
the default is signed, which has both negative and positive values!}\\
\hline
Other Types in C & 
\vspace{2mm}
\begin{itemize}
  \item \textcolor{teal}{Array-Types}
  \item \textcolor{teal}{Struct-Types}
  \item \textcolor{teal}{Union-Types}
  \item \textcolor{teal}{Pointer-Types}
  \item \textcolor{teal}{Function-Types}
  \vspace{-3mm}
\end{itemize}\\
\hline
Pointer types& 
\textcolor{orange}{\textbf{A pointer is just a number, it is an integer}}\newline
\textcolor{teal}{They simply \emph{point} to an address, this an be any address even another pointer address!}
\begin{lstlisting}
int num = 5;
int* nump; // pointer to int
int num2 = *nump; 
// dereference the pointer and assign the value of it to num2
int** numpp = &nump;
// create a pointer to a pointer with the address of nump
\end{lstlisting}
\\
\hline
Decimal,Octal and Hex & 
\vspace{2mm}
\begin{itemize}
  \item \textcolor{teal}{Decimal: 0..9 with \textbf{NO 0 at the start}} 
  \item \textcolor{teal}{Octal: 0..7 with a \textbf{leading 0}} 
  \item \textcolor{teal}{Hex: 0..F with \textbf{0x at the start}} 
  \item \textcolor{teal}{Suffix: the suffix specifies the type:}\newline
    l long,ll long long ,u unsigned,ul .. ,ull ..
  \vspace{-3mm}
\end{itemize}\\
\hline
Casts & 
\textcolor{orange}{Casts are just like in c++}\newline
\begin{lstlisting}
double ping = 5.5;
int pang = (int)ping;
\end{lstlisting}
\, \newline
\textcolor{OliveGreen}{Casting is usually the result of bad software design and should be avoided if possible,\newline
however, sometimes it is needed like with precisions in multiplication!}\\
\hline
Bitwise Operators & 
\vspace{2mm}
\begin{itemize}
  \item \textcolor{teal}{not: \(\tilde{} \) q}
  \item \textcolor{teal}{and: q \& p }
  \item \textcolor{teal}{or: q | p}
  \item \textcolor{teal}{or: q \^ p}
  \item \textcolor{teal}{or: q << p} left shift
  \item \textcolor{teal}{or: q >> p} right shift
\end{itemize}
\, \newline
\textcolor{teal}{Bitwise operators always return the same type we entered!}\newline 
\textcolor{orange}{Unlike assembly, you can't use rotate directly!} \\
\hline
Arithmic Operators& 
\vspace{2mm}
\begin{itemize}
  \item \textcolor{teal}{not: !q}
  \item \textcolor{teal}{and: q \&\& p}
  \item \textcolor{teal}{or: q || p}
  \item \textcolor{teal}{greater than: >}
  \item \textcolor{teal}{smaller than: <}
  \item \textcolor{teal}{greater than or equal: >=}
  \item \textcolor{teal}{smaller than or equal: <=}
\end{itemize}
\, \newline
\textcolor{red}{\textbf{The return type of these is int NOT bool!}}\newline
The reason for this is that C is a very old language and bool didn't exist when it was created.\\
\hline
Function parameters in C &
\textcolor{orange}{C handles function parameters in a weird way, you can call a function with no parameters with any amount of parameters. If you want to explicitly state that you do not want any parameters, then you need to include the parameter "void" in the declaration. C++ doesn't do this!}\newline
\begin{lstlisting}
void f();
void b(void);
// formatting to keep the lines shorter
void f() { printf("pangping!"); } // ok
void f(1,2,3,4) { printf("pangping!"); } // ok LMAO
void b() { printf("pangping!"); } // ok
void b(1,2,3,4) { printf("pangping!"); } // !!ERROR!!
\end{lstlisting}\\
\hline
Copy by default & 
\textcolor{orange}{Just like c++ all parameters will be copied by default, if you want to use the same object, use pointers! \textbf{yes RAW POINTERS not references! That is another c++ feature!}}\newline
\begin{lstlisting}
int x = 5;
void f(int x) {
  x = x + 1;
} // x is still 5 as the parameter was copied!
void b(int *x) {
  *x = *x + 1;
} // now x is 6 as we used the pointer!
\end{lstlisting}\\
\hline
Global vs Local variables & 
\textcolor{orange}{Global variables will always be \textbf{initialized as 0 if we do not initialize it ourselves!}}\newline
\textcolor{purple}{Local variables on the other hand \textbf{will not be initialized by the compiler, aka it will be the value that the memory address it has at that point!}}\newline
\textcolor{teal}{The simple reason for this, is that the global variables are allocated on the heap, they have a fixed memory address, where as the local variables are on the stack!}\\
\hline
Function Pointers & 
\textcolor{orange}{Functions can be called by using pointers, quite nice:}\newline
\begin{lstlisting}
int g ( int x , int y );

int (*p) (int, int) = &f ;
p = g;
i = (*p) (1, 2); // calls the function g with parameters (1, 2)
j = p(3, 4); // same
\end{lstlisting}\\
\hline
\end{tabular}
\end{table}
\pagebreak 
\begin{table}[ht!]
\section{Pointers in C}
\begin{tabular}{|m{0.2\linewidth}|m{0.755\linewidth}|}
\hline
Raw Pointers & 
Just like c++:\newline
\begin{lstlisting}
int32_t j = 10;
int32_t *y = &j;
// y now points to j

y++;
// y skips 4 bytes as int32_t has size of 4 bytes!
// also note that this is pointer is now pointing to trash data!!
\end{lstlisting}\\
\hline
Index-Operators with Pointers & 
For whatever reason this is possible, note that \textbf{one operand needs bo be a pointer and one needs to be an integer! But it doesn't matter which one!}\newline
\begin{lstlisting}
a[b] == *(a+b)
int32_t x = 0;
int32_t * y = & x ;
y[0] = 0x42 ;     // same as : x = 0 x42
(&x)[0] = 0x42 ; // same
0[&x] = 0x42 ;   // same
100[200] = 0x42 ;  // Error : no address
\end{lstlisting}\\
\hline
Pointer to Arrays & 
\vspace{2mm}
\begin{lstlisting}
int32_t a[10]; // array with 10 integers
int* b[10]; // 10 pointers to ints
void* c[10]; // 10 voidpointers
int* d[3] = {1,2,3}; // array with elements initialized
int* d[] = {1,2,3}; // same but size inferred

// usage
int h = d[2]; // h equal to 3
\end{lstlisting}\\
\hline
sizeof() & 
The sizeof function will \textbf{return the size of the type with regular types like integers and chars}, and it will \textbf{return the length of an array!}\newline
\begin{lstlisting}
int g = 8;
int* b[] = {3,4,5,6,7};
printf(%d,g); // prints 8
printf(%d,b); // prints 5 -> the amount of elements
\end{lstlisting}\\
\hline
size\_t & 
size\_t is the return value of sizeof which is big enough to hold any object.\newline
It provides a datatype to iterate over arrays.\newline
\textbf{it's essentially an iterator}\newline
\begin{lstlisting}
for (size_t i = 0; i < something; i++) {
  a[i] = 0;
}
\end{lstlisting}\\
\hline
typdef & 
Typedef are type aliases that can be used when you have a ridiculous long typename.\newline
\begin{lstlisting}
typedef int int_t; // int is int_t type
\end{lstlisting}\\
\hline
Function-Alias &
\vspace{2mm}
\begin{lstlisting}
// Function pointer type with name function_t
// for functions returning an int
// and having one parameter of type pint_t
typedef int (* function_t ) ( pint_t );
int calculate (pint_t);
function_t callback = calculate; // No call
function_t callback2 = &calculate; // same , & is optional
int x = 0;
int y = (*callback) (&x);// calls calculate
\end{lstlisting}\\
\hline
Predefined Aliases & 
There are a bunch of aliases that are predefined:\newline
\begin{itemize}
\item \textcolor{purple}{int8\_t, int16\_t, int32\_t, int64\_t}
\item \textcolor{purple}{intmax\_t: biggest signed integer}
\item \textcolor{purple}{untptr\_t: signed integer which its into an address}
\item \textcolor{purple}{uint8\_t, ..., uintmax\_t: ungsigned variants of above}
\item \textcolor{purple}{size\_t: result type of sizeof(t)}
\vspace{-3mm}
\end{itemize}\\ 
\hline
Subtraction on Pointers & 
You can only subtract pointers when they are of equal size\_t, this means the underlying type needs to be same!\newline
\begin{lstlisting}
int32_t *a = 100;
int32_t *b = 120;
uint32_t *c = 140;
ptrdiff_t y = a - b; // ok
prtdriff_t z = a - c; // ERROR signed and unsgined not the same!
\end{lstlisting}\\
\hline
Strings in C & 
In C we do not have a standard string, instead we need to use a char array:\newline
\begin{lstlisting}
// explicitly with array
char s [] = { 'H ' , 'a ' , 'i ' , '\0 ' };
// same as char s [] = { ' H ', 'a ', 'i ', 0};
char *pc = s ;

// implicitly with pointer
char *s = "Hai"; //best version
while (*pc != '\0') {
  // do something
  ++ pc ;
}
\end{lstlisting}\\
\hline
\end{tabular}
\end{table}
\pagebreak
\begin{table}[ht!]
\begin{tabular}{|m{0.2\linewidth}|m{0.755\linewidth}|}
\hline
Arrays as parameters & 
You can't be passed by value as a whole, instead you pass the pointer, \textbf{even when the parameter type is declared as a full array!}\newline
\begin{lstlisting}
int f ( int * a ) { /* ... */ }  // passes pointer
int f ( int a []) { /* ... */ }  // passes pointer
int f ( int a [4]) { /* ... */ } // passes pointer
\end{lstlisting}\\
\hline
Arrays will not know about their size & 
This means that you will need to pass an additional parameter in order for you to iterate over the array!\newline
\begin{lstlisting}
int some_func (int *a, int n) {
  for (int i = 0; i < n; ++i) {
    a [i] = 0;
  }
}
// small note, with char* [] you can ommit this parameter,
// as the last char will always be the terminating char \0 !
\end{lstlisting}
\, \newline
\textcolor{red}{There is a small problem with strings should you NOT pass the size parameter, it could potentially lead to reading of unowned memory -> overread exploit,\newline
in case the null termination won't happen!}\\
\hline
const & 
const simply means that \textbf{you can't change the value, but other functions etc might be able to change it!}\newline
This is in contrast to C++ and rust which both define something to be universally const if defined as const.\newline
\textcolor{OliveGreen}{Also, the const will always be for the type on the left of the const word, this means you can make a pointer to a const type,\newline
or you can make a const pointer:}\newline
\begin{lstlisting}
char const *c; // Pointer to const char
char *const d;     // const Pointer to char
++c;               // OK : c is pointer
5 ++d;             // Error : d is const pointer
6 *c = 'a';        // Error : * c is const char
7 *d = 'a';        // OK : * c is char
\end{lstlisting}\\
\hline
Predefined String operations &
\begin{itemize}
  \item \textcolor{purple}{size\_t strlen (char const *str, size\_t max)}\newline
  returns the length of the string
\item \textcolor{purple}{int strcmp (char const *a, char const *b)}\newline
  compares the string by comparing each char from left to right
\vspace{-3mm}
\end{itemize}\\ 
\hline
Structs & 
Structs are the same as in C++, without the additional benefits of methods etc, as C does not have classes and is not an OOP language.\newline
\begin{lstlisting}
// with names
struct something {
  char c;
  int b; 
  // more...
} t; // explained below
// without names, used for global variables... 
struct {
  int q; 
  // ...
}; // exlained below

struct something myStruct; // both names are necessary to instantiate a struct in C!!
\end{lstlisting}
\, \newline
\textcolor{OliveGreen}{The \textbf{t is an instance of the struct, in other words it defines a variable with that name already!}}\newline
\textcolor{red}{Also note that instantiating a struct requires the full name as follows: \textbf{struct structname variablename}!!}\\
\hline
Accessing members of structs & 
It is just like c++ with a dot in case of a full variable, or an arrow in case of a pointer: \newline
\begin{lstlisting}
struct something a;
struct something *b;
a.c = 'H';
a.b = 10;
b->c = 'E';
b->b = 50; 
// or with a list 
struct something c = {'A', 3};
\end{lstlisting}\\
\hline
Complete vs Incomplete types & 
A type is considered \textbf{complete if you know the size at compiletime}, otherwise the type is \textbf{considered incomplete when it has an unknown size at compile time.}\newline
\textbf{Incomplete types} need to be stored \textbf{on the heap!}\\
\hline
Forward Declaration & 
Sometimes you want need to declare something, then use it, but finish it later on to make it a complete type, in this case you can split the full declaration:\newline
\begin{lstlisting}
struct Folder ; // Forward - Deklaration
struct File {
  struct Folder * parent ; // OK : all pointer types have same size
  char name [256];         // OK : fixed size array
}; // --> Type complete
struct Folder {
  struct File * file [256]; // OK : fixed size array
}; // --> Type complete
\end{lstlisting}\\
\hline
Implicit integer conversion & 
Integers will always be implicitly converted to each other, this can lead to cases where the compiler will subtract \(2^n\) numbers until the conversion will work.\newline
\textbf{It is therefore recommended to only use explicit conversion rather than using implicit ones!}\\
\hline
\end{tabular}
\end{table}
\pagebreak
\begin{table}[ht!]
\begin{tabular}{|m{0.2\linewidth}|m{0.755\linewidth}|}
\hline
Void pointer & 
As all pointers are just memory addresses, you can always \textbf{implicitly cast a void pointer into a typed one and back!}\newline
\textcolor{red}{However, this needs serious caution, as interpreting data as anohter type might bring issues and security vulnerabilities!}\newline
\begin{lstlisting}
int x;
int *px = &x;
void *p = px;
px = *p;
\end{lstlisting}\\
\hline
Testing for nullptr & 
Nullpointers in C are tested with the actual value 0:\newline
\begin{lstlisting}
if (pointer == 0) {
  // ...
}
\end{lstlisting}\\
\hline
Union & 
Unions are essentially enums from rust without the ability to create methods or use traits.\newline
\textcolor{OliveGreen}{Members of unions therefore always start at the same address as the union and each union has the same size, just like in c++ and rust, it is equal to the biggest possible union member.}\newline
\begin{lstlisting}
union U {
  int kind ;
  struct { int kind; char value [256]; } str;
  struct { int kind; long long value ; } ll;
};
union U u1 = {.ll = {.kind = 27, .value = 0x12345}};
union U u2 = {.str = {.kind = 15, .value = "Hello"}};
union U *pu = &u2;
if (pu - > kind == 15) { puts ( pu - > str . value);}
if (pu->kind == 27) {printf("%llX", pu->ll.value);}
\end{lstlisting}\\
\hline

\hline

\hline

\hline

\hline

\hline

\hline

\hline
\end{tabular}
\end{table}
\pagebreak
\begin{table}[ht!]
\begin{tabular}{|m{0.2\linewidth}|m{0.755\linewidth}|}
\hline
\textbf{Imul vs Mul} & 
\textcolor{orange}{(C) In case of 2 unsigned integers, we should technically use the mul instruction,\newline
however, the compiler will often use the imul instruction instead as it is better for optimization!\newline
The reason for the imul usage, is that 2 negative numbers would result in the same operation as 2 regular numbers\newline 
therefore 2 normal numbers will result in the same operation!}\newline
\textcolor{red}{Important with imul the signed integers will be treated as negative! But AGAIN this does \textbf{NOT} matter!!!}\\
\hline
\textbf{Carry Flag} & 
\textcolor{orange}{The carry flag signifies the \textbf{overflow with unsigned integers!}}\newline
\textcolor{teal}{0001 + 1111 = 0000 AND CF = 1 -> 1 + 15 = 0 -> CF = 1}\\ 
\hline
\textbf{Overflow Flag} & 
\textcolor{orange}{The  overflow flag signifies the \textbf{overflow with signed integers!}}\newline
\textcolor{teal}{0111 + 0001 = 1000 -> 7 + 1 = -8 (only 3 bits are for data!! first bit is the signature!!)}\\
\hline
CF vs OF &
\textcolor{red}{The compiler can't distinguish between unsigned or signed for a number, this is why it always sets both flags, later on the compiler needs to use the right one.\newline
This means on overflow, both values are set and then later on the right flag will be used based on the variable!}\\
\hline
\textbf{FlagList} & 
\vspace{2mm}
\begin{itemize}
\item \textcolor{teal}{CF:} Carry Flag, overflow for unsigned integers 
\item \textcolor{teal}{OF:} Overflow Flag, overflow for signed integers
\item \textcolor{teal}{ZF:} Zero Flag, will be set when the result is 0
\item \textcolor{teal}{SF:} Sign Flag, is the highest bit of the result -> leftmost byte (little endian)
\item \textcolor{teal}{PF:} Parity Flag, set if the lowest byte has an even number of bits
\vspace{-3mm}
\end{itemize}\\
\hline
\textbf{Condition Codes (CC)} & 
\textcolor{orange}{Certain instructions will only be used when a combination of flags is given -> Condition Code}\newline
\textcolor{teal}{Example: condition "Above" -> CF = 0 AND ZF = 0}\newline
\textcolor{green}{List of CC:}\newline
\begin{tabular}{|ll|ll|}
\hline
\textcolor{teal}{A : Above }& \textcolor{teal}{ -> CF = 0 AND ZF = 0}&
\textcolor{teal}{AE: Above or Equal } & \textcolor{teal}{ -> CF = 0}\\
\textcolor{teal}{B : Below } & \textcolor{teal}{ -> CF = 1}&
\textcolor{teal}{BE: Below or Equal } & \textcolor{teal}{ -> CF = 1 AND ZF = 1}\\
\textcolor{teal}{E : Equal }& \textcolor{teal}{ -> ZF = 1}&
\textcolor{teal}{G : Greater }& \textcolor{teal}{ -> SF = OF = 0 AND ZF = 0}\\
\textcolor{teal}{GE: Greater or Equal }& \textcolor{teal}{ -> SF = OF}&
\textcolor{teal}{L : Less }& \textcolor{teal}{ -> SF != OF}\\
\textcolor{teal}{LE: Less or Equal }& \textcolor{teal}{ -> SF != OF AND ZF = 1}&
\textcolor{teal}{PE: Parity Even} & \textcolor{teal}{ -> PF =1}\\
\textcolor{teal}{PO: Parity Old } & \textcolor{teal}{ -> PF = 0}&
\textcolor{teal}{Z:  Zero}&\textcolor{teal}{ -> ZF = 1} \\
\end{tabular}
\\
\hline
\end{tabular}
\end{table}
\pagebreak
\begin{table}[ht!]
\begin{tabular}{|m{0.2\linewidth}|m{0.755\linewidth}|}
\hline
Jumps & 
\textcolor{orange}{This is essentially goto!}\newline
\begin{lstlisting}
jmp 230 ; moves 230 down 
jmp -230 ; moves 230 up
; We can also jump to labels!!!!
  mov eax, [x]
  cmp eax, 3
  jne label1 ; jump to label1 if eax not equal to 3
  mov eax, [y]
  
label1: 
  inc eax
\end{lstlisting}\\
\hline
Conditional Mov & 
\textcolor{orange}{cmovCC: mov if condition is met! \textbf{the cc stands for the code!}}\newline
\begin{lstlisting}
mov rax, [ux]
mov rbx, [uy]
cmp rax, rbx
cmove rcx, 5 ; move 5 into rcx if rax and rbx are equal!
\end{lstlisting}\\
\hline
Conditional JMP & 
\textcolor{orange}{jCC: jmp if condition is met! \textbf{the cc stands for the code!}}\newline
\begin{lstlisting}
cmp rax, rbx
je 230 ; move 230 down if rax and rbx are equal
\end{lstlisting}\\
\hline
Conditional SET &
\textcolor{orange}{setCC: set if condition is met! \textbf{the cc stands for the code!}}\newline
\begin{lstlisting}

\end{lstlisting}\\
\hline
If Else & 
\begin{lstlisting}
mov eax, [ux]
cmp eax, 2 
ja else_body ; jump to else statements if condition is met

jmp after_if ; will only be hit when condition at "ja" was false

else_body: 
; will only be hit if condition at "ja" was true
after_if:
; will be hit by everything
\end{lstlisting}\\
\hline
do while in assembly & 
\textcolor{red}{The do while loop is the worst loop possible according to the professor. lol}\newline
\begin{lstlisting}
loop: 
  dec rcx
  jnz loop ; if rcx not z, go to loop
\end{lstlisting}\\
\hline
While in assembly & 
\begin{lstlisting}
mov rcx, 23 
jmp condition 

loop: 
  ; body -> do something 
condition: 
  dec rcx 
  jnz loop ; move to loop if rcx not 0
\end{lstlisting}\\
\hline
For in assembly & 
\begin{lstlisting}
mov rcx, 0

loop: 

  inc rcx
condition: 
  cmp rcx 10
  jle loop
\end{lstlisting}\\
\hline
Pointer-Addition in assembly & 
\pic{2022-10-25-04:40:00.png}\newline
\textcolor{teal}{We can add additional bytes to a pointer. \newline
in C: int *p = 0x20; -> p+1 == 0x24 -> p+2 == 0x28\newline
or simply use the ++p for the same as p+1}
\, \newline
\begin{lstlisting}
extern int *begin; // defined somewhere else 
extern int *end;   // defined somewhere else 
int sum = 0;
for (int *p = begin; p != end; ++p) {
sum += *p; // same as regular for loop just with pointer instead
 ;// then dereference the pointer here to get the value 
 ;// warning, if you go beyong what you should -> undefined behavior, likely segmentation fault!
}
\end{lstlisting}
\\
\hline
\end{tabular}
\end{table}
\pagebreak
\begin{table}[ht!]
\begin{tabular}{|m{0.2\linewidth}|m{0.755\linewidth}|}
\hline
Functions in assembly & 
\begin{lstlisting}
mov [opa_and512], op1a
mov [opb_and512], op1b
mov [res_and512], res1
mov [raddr_and512], after1
;the idea is that we store after 1 and go there when needed
and512:
    xor rcx, rcx

loop_and512:
    mov rax, [opa_and512 + 8 * rcx]
    mov rax, [opb_and512 + 8 * rcx]
    mov [res_adn512 + 8 * rcx], rax

    inc rcx
    cmp rcx, 8 
    jne loop_and512
    jmp [raddr_and512] ; move to after1

after1:
    ;do something
\end{lstlisting} 
\, \newline
\textcolor{orange}{We have an obvious problem with this, if we want to do a recursive function, we would need to define multiple global functions in order to get the proper behavior.}\newline
\begin{lstlisting}
S: 
    test rax, rax ;n == 0?
    js rsi

    mov rcx, rax
    dec rax
    mov rsi, after ; set rsi to after
    jump S 

after: 
    add rax, rcx ; as soon as we hit this code we have an endless loop!
    ; potential fix another register rso to after2:
    ; if ok jump to rso
    jump rsi
after2:
    ; do more
\end{lstlisting}
\, \newline
\textcolor{orange}{So what we would like to have is something like a stack:}\newline
\textcolor{orange}{Stack Push}\newline
\includegraphics[scale=0.4]{2022-11-08-03:34:38.png}
\includegraphics[scale=0.4]{2022-11-08-03:34:50.png}
\includegraphics[scale=0.4]{2022-11-08-03:34:43.png}\newline
\textcolor{orange}{Stack Pop}\newline
\includegraphics[scale=0.4]{2022-11-08-03:35:28.png}
\includegraphics[scale=0.4]{2022-11-08-03:35:38.png}
\includegraphics[scale=0.4]{2022-11-08-03:35:33.png}\newline
\textcolor{red}{IMPORTANT: The stack memory address decreases from top to bottom!!}\newline
\begin{lstlisting}
S: 
    test rax, rax ;n == 0?
    js rsi

    push rax
    dec rax
    push after
    jump S 

after: 
    pop rcx
    add rax, rcx
after2:
    pop rsi
    jmp rsi
\end{lstlisting}\\
\hline
call and ret & 
\textcolor{orange}{These are simply a combination of either push and jmp or pop and jmp:}\newline
\begin{itemize}
\item \textcolor{orange}{call = push rax and jmp a}
\item \textcolor{orange}{ret = pop rax and jmp rax}
\vspace{-2mm}
\end{itemize} 
\begin{lstlisting}
S: 
    test rax, rax
    jz final ; goto final if n == 0

    push rax
    dec rax
    call S ; goto S
    ; final will return here !!
    pop rcx 
    add rax, rcx
    ret ; return after we went to final 
final:
    ret ; return after where called
\end{lstlisting}\\
\hline
\end{tabular}
\end{table}
\pagebreak
\begin{table}[ht!]
\begin{tabular}{|m{0.2\linewidth}|m{0.755\linewidth}|}
\hline
Parameters on Stack & 
\textcolor{orange}{When we want to jump to a function, we first push the function to jump to in the stack, then its arguments, and then the return function.\newline
This means that the parameters will be on the stack until you return from the function.}\\
\hline
Frame Pointer & 
\textcolor{orange}{With each function call, the \textbf{frame pointer} will move back and forth,\newline
this requires a stable register for the frame pointer, this is the register \textbf{RBP (Base Pointer) on inte64}}\newline
\textcolor{teal}{Prolog}\newline
\begin{lstlisting}
push rpb ;push base pointer to stack
mov rbp, rsp ;rsp into rpb
\end{lstlisting} 
\, \newline
\textcolor{teal}{Epilog}\newline
\begin{lstlisting}
mov rsp, rpb ; move rpb into rsp 
pop rbp ; pop rbp from stack
\end{lstlisting}\\
\hline
Stack Allocation& 
\textcolor{orange}{You don't allocate or de-allocate every single variable one by one, instead you allocate or de-allocate it all at once:}\newline
\begin{lstlisting}
sub rsp, 0x20 ; allocates 0x20 bytes on stack
add rsp, 0x20 ; deallocates 0x20 bytes on stack
\end{lstlisting} 
\, \newline
\textcolor{orange}{You can then access the current result that is over the frame pointer like this:}\newline
\begin{lstlisting}
mov rcx, [rbp - 0x8] ; access memory for results
\end{lstlisting}\\
\hline
Parameters in Assembly & 
\textcolor{orange}{Since we do not have an integrated concept of functions, we need to handle the parameter passing ourselves.}\newline
\textcolor{purple}{Here we first push the parameter on to the stack, then we push the function pointer to the stack, this means that the function pointer is on the top.}\newline
\begin{lstlisting}
f: 
    push[x] // push the parameter to the stack
    call g  // push the function pointer to the stack
g: 
    push rbp 
    mov rbp, rsp 
     
    mov rcx, [rpb + 0x10]

    mov rsp, rbp 
    pop rbp 
    ret
\end{lstlisting}\\
\hline
Calling Conventions & 
\textcolor{orange}{The calling convention is the contract between the caller and the callee, it needs to define how the parameters will be passed, how the return values will be handled and how the stack will be built/reduced.}\newline
\textcolor{purple}{This can either be between a function and another function, or between a program and the operating system.}\\
\hline

\hline

\hline

\hline
\end{tabular}
\end{table}
\pagebreak
\begin{table}[ht!]
\begin{tabular}{|m{0.2\linewidth}|m{0.755\linewidth}|}
\hline

\hline

\hline

\hline

\hline

\hline

\hline

\hline

\hline

\hline

\hline
\end{tabular}
\end{table}
\pagebreak
\begin{table}[ht!]
\begin{tabular}{|m{0.2\linewidth}|m{0.755\linewidth}|}
\hline

\hline

\hline

\hline

\hline

\hline

\hline

\hline

\hline

\hline

\hline
\end{tabular}
\end{table}
\end{document}
